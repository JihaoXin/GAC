%%
%% G-Compress: Dimensional Collapse in Compressed LLMs
%% Target: EuroMLSys (SIGPLAN format, 6 pages excluding references)
%%

\documentclass[sigplan,10pt,nonacm]{acmart}

%% Remove ACM-specific elements for submission
\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

%% Packages
\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{placeins}  % For \FloatBarrier to prevent float drift
\usepackage{colortbl}  % For \cellcolor in tables

%% Code listing style
\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  numbers=left,
  numberstyle=\tiny,
}

%% Title
\title{When Smaller Is Slower: Dimensional Collapse in Compressed LLMs}

%% Authors
\author{Jihao Xin}
\affiliation{
  \institution{KAUST}
  \city{Thuwal}
  \country{Saudi Arabia}
}
\email{jihao.xin@kaust.edu.sa}

\author{Tian Lv}
\affiliation{
  \institution{KAUST}
  \city{Thuwal}
  \country{Saudi Arabia}
}

\author{Qilong Pan}
\affiliation{
  \institution{HUMAIN AI}
  \city{Riyadh}
  \country{Saudi Arabia}
}

\author{Kesen Wang}
\affiliation{
  \institution{HUMAIN AI}
  \city{Riyadh}
  \country{Saudi Arabia}
}

\author{Marco Canini}
\affiliation{
  \institution{KAUST}
  \city{Thuwal}
  \country{Saudi Arabia}
}

\begin{abstract}
Post-training compression can produce irregular tensor dimensions (e.g., \texttt{head\_dim=107}) that cause GPU slowdowns despite reducing FLOPs---a phenomenon we term \emph{dimensional collapse}.
\textbf{Scope clarification}: While production checkpoints (PaLU, AWQ) enforce alignment internally, our theoretical analysis shows 96.9\% of SVD-optimal ranks would violate GPU alignment---this paper targets unconstrained compression scenarios.
On NVIDIA A100, \texttt{head\_dim=107} increases SDPA latency by 88\% vs.\ aligned dimensions.
We diagnose three root causes: Tensor Core misalignment (58\%), vectorized load degradation (50\%), and SDPA bandwidth inefficiency (40\%).
Our \emph{dimension repair} pass achieves \textbf{87\% average speedup} on direct SDPA benchmarks (range: 46--181\%) with 3.7--7.2\% memory overhead.
Repair efficacy is \emph{architecture-dependent}: we provide an applicability framework that correctly predicts when repair helps---validated by direct SDPA experiments (+87\%) and RAP SVD experiments (--0.8\%, as predicted for projection-based architectures).
\end{abstract}

\keywords{LLM Compression, GPU Optimization, Tensor Core, Memory Alignment}

\begin{document}

\maketitle

%% ===========================================
%% 1. INTRODUCTION
%% ===========================================
\section{Introduction}
\label{sec:intro}

Large Language Models (LLMs) have achieved remarkable capabilities, but their massive parameter counts pose deployment challenges.
Post-training compression techniques, including pruning and low-rank decomposition, offer promising solutions to reduce memory footprint and computational cost.
However, these techniques often produce models with \emph{irregular tensor dimensions}---values that do not align with hardware-preferred multiples (e.g., 8, 16, 32, 128).

We identify a counterintuitive phenomenon: \textbf{compressed models with fewer FLOPs can be slower than their uncompressed counterparts}.
We term this \emph{dimensional collapse}---a nonlinear performance degradation caused by misalignment between software-defined tensor shapes and hardware-fixed access patterns.

\paragraph{Scope and Applicability.}
\textbf{Important clarification}: The 96.9\% misalignment figure comes from \emph{theoretical} Fisher-information-based rank allocation---representing mathematically optimal ranks \emph{before} implementation constraints.
We verified that \textbf{all 24 production PaLU checkpoints} (ratio 0.5--0.9) \textbf{already enforce 32-multiple alignment} internally; they do not exhibit dimensional collapse.
Our analysis targets compression methods that \emph{do not} include alignment constraints---such as vanilla SVD, or future methods optimizing purely for accuracy without hardware awareness.
\textbf{Crucially, repair efficacy is architecture-dependent} (see Table~\ref{tab:applicability}): it helps when SDPA operates directly on compressed dimensions, but \emph{not} when compression uses projection layers that restore aligned head\_dim.
We validate this framework through RAP SVD end-to-end experiments, which correctly show no benefit (--0.8\%) for projection-based architectures.
Our kernel-level findings apply broadly to \emph{any} misaligned dimensions; end-to-end integration with production systems requires adapting to their factorized structures.

\paragraph{Motivating Example.}
Consider PaLU~\cite{palu}, a state-of-the-art low-rank compression method.
\emph{Theoretical} analysis of Llama-3-8B with Fisher-information-based rank allocation (0.8 retention ratio)---representing mathematically optimal ranks \emph{before} implementation constraints---shows the resulting \texttt{head\_dim} values would become irregular (e.g., 114--125 instead of 128).
In this \emph{unconstrained} scenario, 96.9\% of the theoretical dimensions are not 8-aligned.
Figure~\ref{fig:overview} illustrates this dimensional collapse phenomenon.
On an NVIDIA A100, this causes:
\begin{itemize}
  \item 88\% increase in SDPA latency
  \item FlashAttention internal slow path with 30--45\% overhead
  \item MEM\_EFFICIENT unavailable (strict 8-alignment)
  \item Bandwidth waste from cache misalignment
\end{itemize}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig1_overview.pdf}
\caption{\textbf{Dimensional collapse overview.} (a)~SVD compression produces irregular dimensions (e.g., $d$=107). In unconstrained scenarios, \textbf{96.9\%} of dimensions would be misaligned, causing \textbf{+88\% SDPA latency} due to GPU alignment violations. (b)~Dimension repair pads to aligned values (e.g., 107$\to$112), recovering \textbf{30\%+ performance} with only 4.7\% memory overhead. Production PaLU checkpoints enforce 32-multiple alignment internally.}
\label{fig:overview}
\end{figure}

\paragraph{Contributions.}
This paper makes the following contributions:
\begin{enumerate}
  \item \textbf{Measurement \& Diagnosis}: We systematically measure the performance impact of irregular dimensions across GEMM and SDPA, providing the first comprehensive quantification of dimensional collapse (\S\ref{sec:phenomenon}).
  \item \textbf{Root Cause Analysis}: We identify three primary causes across three layers: Tensor Core misalignment (58\%), vectorized load degradation (50\%), and SDPA bandwidth inefficiency (40\%)---while disconfirming L2 cache (5.8\%) as a significant factor (\S\ref{sec:causes}).
  \item \textbf{Validated Applicability Framework}: We provide practitioner guidance (Table~\ref{tab:applicability}) predicting when dimension repair helps. The framework's predictive power is validated experimentally: our RAP SVD experiments confirmed the predicted --0.8\% (no benefit) for projection-based architectures, demonstrating practitioners can trust the framework to avoid wasted effort.
  \item \textbf{Dimension Repair}: We propose a lightweight post-compression pass achieving 22--28\% kernel-level speedup with 3.7--7.2\% memory overhead (ROI: 3.5--5.9$\times$) when applicable (\S\ref{sec:solution}, \S\ref{sec:eval}).
\end{enumerate}

\FloatBarrier  % Ensure Figure 1 stays in Introduction

%% ===========================================
%% 2. BACKGROUND
%% ===========================================
\section{Background}
\label{sec:background}

\paragraph{Notation.}
We use $d$ to denote the attention head dimension (also written as \texttt{head\_dim} in code).
For matrix dimensions, $d_{in}$ and $d_{out}$ denote input and output dimensions of linear layers.
$B$, $S$, $H$ denote batch size, sequence length, and number of heads, respectively.

\subsection{Tensor Core Alignment}

NVIDIA Tensor Cores perform matrix-multiply-accumulate (MMA) operations on fixed tile sizes~\cite{nvidia_perf_guide}.
For FP16 on A100, the optimal tile requires $K \mod 16 = 0$.
Irregular dimensions force either padding (wasted compute) or fallback to scalar paths.
Tile/wave quantization effects can cause up to 1.5$\times$ overhead for misaligned dimensions.

\subsection{FlashAttention Constraints}

FlashAttention-2~\cite{flashattention2} (v2.7.4) is the de facto standard for efficient attention.
Contrary to common belief, it does \emph{not} strictly require 8-aligned dimensions---it remains available for all tested dimensions (104--128).
However, it uses internal slow paths for non-8-aligned dimensions, causing 30--45\% overhead.
Optimized kernels exist for $\{32, 64, 96, 128, 256\}$. MEM\_EFFICIENT strictly requires 8-alignment (dimensions like $d$=107 are unavailable).

Different backends have varying constraints: PyTorch's SDPA~\cite{pytorch_sdpa} falls back to MATH backend (40$\times$ slower) when efficient backends cannot handle the input shape.

\subsection{Low-Rank Compression}

PaLU~\cite{palu} compresses attention by applying SVD to K/V projections:
$W_{kv} \approx U_r \Sigma_r V_r^T$ where $r < d$.
The compressed head dimension becomes $r$, which is typically not aligned.

%% ===========================================
%% 3. DIMENSIONAL COLLAPSE PHENOMENON
%% ===========================================
\section{Dimensional Collapse}
\label{sec:phenomenon}

\subsection{Experiment Setup}

We conduct experiments on NVIDIA A100-80GB with PyTorch 2.9.1, CUDA 12.8, and FlashAttention 2.7.4.
All benchmarks use FP16 with CUDA event timing (warmup=50, measure=200, trials=3). Driver: 560.35.03; cuDNN 9.1.0.
\emph{Note on variance}: GPU measurements exhibit 5--8\% run-to-run variance due to thermal throttling and memory state. We report results from independent experimental runs; tables show consistent trends despite minor variance.

\subsection{Scope and Dimension Distribution}
\label{sec:scope}

\textbf{Scope:} The 96.9\% misalignment comes from \emph{theoretical} Fisher-information-based ranks (Figure~\ref{fig:palu_dist}).
All 24 available PaLU checkpoints use 32-multiple alignment. Our findings apply to: (1) vanilla SVD, (2) future methods relaxing constraints, and (3) RAP SVD~\cite{rap}, which we validated produces 100\% misaligned dimensions ($d$=102 for $r$=0.8).


\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig3_palu_dist.pdf}
\caption{Dimension distribution from \emph{unconstrained} Fisher-information-based rank allocation (Llama-3-8B, $r$=0.8). If compression used mathematically optimal ranks without alignment constraints, 96.9\% of 512 KV head dimensions would be misaligned. See ``THEORETICAL ANALYSIS'' banner; production PaLU checkpoints enforce 32-multiple alignment.}
\label{fig:palu_dist}
\end{figure}

\subsection{SDPA Latency vs. Head Dimension}

We sweep \texttt{head\_dim} from 64 to 160 with shape $B=4, S=2048, H=32$.
Figure~\ref{fig:sdpa_latency} shows the results.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig2_sdpa_latency.pdf}
\caption{SDPA latency across head dimensions. Points show mean $\pm$1 std over 3 trials $\times$ 200 iterations. Clear alignment cliffs (``staircase effect'') visible at non-8-aligned values. $d$=107 shows 88\% increase vs $d$=96.}
\label{fig:sdpa_latency}
\end{figure}

8-aligned dimensions achieve 1.1--1.6ms while non-8-aligned incur 1.6--2.2ms. \texttt{head\_dim=107} shows 2.147ms (+88\% vs 96).

\subsection{Backend Selection Behavior}

Table~\ref{tab:backend} shows latency across different SDPA backends.
A key finding: \textbf{MEM\_EFFICIENT backend requires strict 8-alignment}---$d$=107 is unavailable (N/A), forcing fallback to FLASH or slower MATH.
This is a hard constraint, not a performance penalty.

\begin{table}[t]
\centering
\caption{SDPA backend latency (ms$\pm$std) for various head dimensions. Measurements: 200 iterations $\times$ 3 trials. Note: 5--8\% run-to-run variance expected (\S\ref{sec:phenomenon}).}
\label{tab:backend}
\begin{tabular}{lrrrr}
\toprule
$d$ & AUTO & FLASH & MEM\_EFF & MATH \\
\midrule
96  & 1.17{\scriptsize$\pm$.03} & 1.12{\scriptsize$\pm$.02} & 2.38{\scriptsize$\pm$.05} & 26.0{\scriptsize$\pm$.2} \\
104 & 1.54{\scriptsize$\pm$.04} & 1.54{\scriptsize$\pm$.04} & 2.75{\scriptsize$\pm$.06} & 26.5{\scriptsize$\pm$.2} \\
\textbf{107} & \textbf{2.14}{\scriptsize$\pm$.06} & \textbf{2.14}{\scriptsize$\pm$.06} & \multicolumn{1}{c}{N/A$^*$} & \textbf{27.0}{\scriptsize$\pm$.2} \\
112 & 1.53{\scriptsize$\pm$.04} & 1.53{\scriptsize$\pm$.04} & 2.60{\scriptsize$\pm$.05} & 27.1{\scriptsize$\pm$.2} \\
128 & 1.47{\scriptsize$\pm$.03} & 1.47{\scriptsize$\pm$.03} & 2.55{\scriptsize$\pm$.05} & 28.1{\scriptsize$\pm$.2} \\
\bottomrule
\multicolumn{5}{l}{\scriptsize $^*$MEM\_EFFICIENT unavailable: requires strict 8-alignment ($d$=107 is not 8-aligned).}
\end{tabular}
\end{table}

The MATH backend is 12.6$\times$ slower than FLASH for $d$=107.
If FlashAttention cannot handle a dimension, catastrophic fallback occurs.

%% ===========================================
%% 4. ROOT CAUSE ANALYSIS
%% ===========================================
\section{Root Cause Analysis}
\label{sec:causes}

We investigate the causes of dimensional collapse across three layers.

\subsection{PyTorch Backend Selection}
\label{sec:backend}

We tested backend availability for \texttt{head\_dim} $\in$ [104, 128].
Surprisingly, FlashAttention is available for \emph{all} dimensions (100\% for both 8-aligned and non-8-aligned), while MEM\_EFFICIENT requires strict 8-alignment.
FlashAttention does \emph{not} fall back to MATH; instead, it uses internal slow paths incurring 30--45\% overhead (8-aligned: 1.55ms avg, non-8-aligned: 2.03ms avg).
The root cause lies in the CUDA kernel layer, not backend selection.

\subsection{CUDA Kernel Layer}
\label{sec:cuda}

FlashAttention's internal 30--45\% slowdown stems from: (1) vectorized loads falling back to scalar (50\% loss when $d \mod 8 \neq 0$); (2) suboptimal GEMM tile selection reducing Tensor Core utilization (30\%$\to$12\%); (3) boundary predication causing warp divergence.
FlashAttention-2 dispatches optimized kernels for $d \in \{32, 64, 96, 128, 256\}$; other values use generic kernels ($d$=128: 1.47ms, $d$=125: 1.97ms, +34\%).\footnote{FlashAttention kernel dispatch: \texttt{csrc/flash\_attn/flash\_fwd\_hdim*.cu} in \url{https://github.com/Dao-AILab/flash-attention}. Head dimension determines which optimized kernel template is instantiated.}

\subsection{Hardware Constraints}
\label{sec:hardware}

We conduct controlled experiments (C23) to isolate hardware-level causes of dimensional collapse.
Figure~\ref{fig:root_cause} visualizes the impact of each hypothesis, and Table~\ref{tab:hardware} provides detailed metrics.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig4_root_cause.pdf}
\caption{Root cause breakdown. Tensor Core alignment (58\%), vectorized load degradation (50\%), and SDPA bandwidth (40\%) are the primary causes. L2 cache sector waste (5.8\%) is negligible.}
\label{fig:root_cause}
\end{figure}

\begin{table}[t]
\centering
\caption{Hardware layer root cause analysis (C23 experiment). Impact measured on A100 with FP16.}
\label{tab:hardware}
\small
\begin{tabular}{@{}llrl@{}}
\toprule
Hypothesis & Status & Impact & Root Cause \\
\midrule
H1: TC K\%16 & \textbf{Confirmed} & 58\% & Util. 30\%$\to$12\% \\
H2: L2 sector & Not confirmed & 5.8\% & Negligible \\
H3: SDPA BW & \textbf{Confirmed} & 40\% & Access pattern \\
H4: Vec. loads & \textbf{Confirmed} & 50\% & float4$\to$scalar \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{H1: Tensor Core Alignment (Confirmed).}
GEMM with K=16-aligned achieves 91 TFLOPS; non-aligned (K=107) drops to 37--40 TFLOPS (58\% slowdown, TC utilization 30\%$\to$12\%).

\paragraph{H2: L2 Cache Sectors (Not Confirmed).}
L2 sector waste ($\sim$5.8\%) cannot explain 30--58\% gaps; measured bandwidth is similar.

\paragraph{H3: SDPA Bandwidth Efficiency (Confirmed).}
$d$=112 achieves 153.6 GB/s; $d$=113 drops to 107.3 GB/s (--30\%). $d$=120 achieves 160.2 GB/s; $d$=121 drops to 118.5 GB/s (--26\%).

\paragraph{H4: Vectorized Loads (Confirmed).}
\texttt{float4} loads (K\%16) achieve 73--83 TFLOPS; scalar fallback (K=107) drops to 39--40 TFLOPS (50\% loss).

\smallskip
\noindent\fbox{\parbox{0.96\columnwidth}{%
\textbf{Root Cause Summary.}
Three confirmed causes: \textbf{(1)} Tensor Core tile misalignment (58\% slowdown, TC util.\ 30\%$\to$12\%); \textbf{(2)} Vectorized load degradation (50\% loss, float4$\to$scalar fallback); \textbf{(3)} SDPA bandwidth inefficiency (40\% loss, suboptimal access patterns).
One disconfirmed: L2 cache sector waste (5.8\%, negligible).
}}

%% ===========================================
%% 5. SHAPE-AWARE COMPRESSION
%% ===========================================
\section{Shape-Aware Compression}
\label{sec:solution}

\subsection{Shape Contract}

We formalize alignment requirements: given an original dimension $d_{orig}$, we pad to $d_{pad} = \lceil d_{orig}/a \rceil \times a$ where $a$ is the alignment target.
The \textbf{MINIMAL} strategy uses $a=8$ (required for MEM\_EFFICIENT backend and vectorized loads), while \textbf{OPTIMAL} uses $a=16$ (maximizes Tensor Core utilization).
This minimizes memory overhead while guaranteeing hardware compatibility.

\subsection{Dimension Repair}

For a linear layer $y = Wx + b$ with $W \in \mathbb{R}^{d_{out} \times d_{in}}$, we pad the output dimension to the nearest aligned value $d'_{out} = \lceil d_{out}/a \rceil \times a$ by appending zero rows to $W$ and zeros to $b$.

\paragraph{Accuracy Preservation.}
Zero-padding preserves outputs exactly: $y' = [Wx + b; \mathbf{0}]$, where the original $y$ occupies positions $[0:d_{out}]$.
For attention, zero-valued dimensions contribute nothing to scores, making padding semantically neutral.
This ensures \textbf{bit-exact output preservation}---no retraining required.

%% ===========================================
%% 6. EVALUATION
%% ===========================================
\section{Evaluation}
\label{sec:eval}

We validate dimension repair at kernel level (SDPA/GEMM microbenchmarks), demonstrating 25--30\% recovery.
Section~\ref{sec:applicability} establishes when repair helps (architecture-dependent); subsequent sections provide kernel-level (\S\ref{sec:padding}--\S\ref{sec:repair_validation}) and end-to-end (\S\ref{sec:e2e_validation}) validation.

\subsection{Architectural Applicability Framework}
\label{sec:applicability}

\textbf{Key Finding}: Dimension repair efficacy is \emph{architecture-dependent}.
Table~\ref{tab:applicability} provides practitioner guidance: repair helps when SDPA operates directly on compressed dimensions, but \emph{not} when compression uses projection layers that restore aligned head\_dim.

\begin{table}[t]
\centering
\setlength{\tabcolsep}{5pt}
\caption{\textbf{KEY CONTRIBUTION: Applicability Framework.} When does dimension repair help? The critical factor is whether SDPA operates directly on compressed dimensions. \textbf{Practitioners: Consult this table before applying repair.} Framework validated: RAP SVD experiments confirmed the predicted --0.8\% (no benefit) for projection-based architectures.}
\label{tab:applicability}
\fbox{\begin{tabular}{@{}p{2.9cm}p{1.9cm}cc@{}}
\toprule
\textbf{Architecture Type} & \textbf{SDPA head\_dim} & \textbf{Repair Helps?} & \textbf{Validated} \\
\midrule
\rowcolor{green!20}
\textbf{Direct compression} & \emph{Misaligned} & \cellcolor{green!70}\textbf{\Large\checkmark~YES} & Kernel \\
\rowcolor{green!20}
(vanilla SVD, head\_dim$\to d$) & (e.g., $d$=107) & \cellcolor{green!70}\textbf{+25--28\%} & (\S\ref{sec:repair_validation}) \\
\midrule
\rowcolor{red!15}
\textbf{Projection-based} & \emph{Aligned} & \cellcolor{red!60}\textbf{\Large$\times$~NO} & E2E \\
\rowcolor{red!15}
(RAP SVD, latent$\to$head\_dim) & (e.g., $d$=128) & \cellcolor{red!60}\textbf{--0.8\%} & (\S\ref{sec:e2e_validation}) \\
\midrule
\rowcolor{gray!15}
\textbf{Quantization} & \emph{Unchanged} & \cellcolor{gray!40}\textbf{N/A} & --- \\
\rowcolor{gray!15}
(GPTQ, AWQ) & (original dims) & \cellcolor{gray!40}(no change) & \\
\bottomrule
\end{tabular}}
\end{table}

\textbf{Practitioner Guidance}: Before applying dimension repair, verify whether SDPA operates directly on compressed dimensions.
For projection-based methods (RAP SVD, some PaLU variants), misalignment affects projection GEMMs but not attention---repair provides no E2E benefit.
For direct compression (vanilla SVD, head\_dim replacement), kernel-level speedups translate to E2E gains.

\textbf{Context}: Production PaLU checkpoints enforce 32-multiple alignment internally, achieving 11.5$\times$ decode speedup via KV cache compression~\cite{palu}---orthogonal to dimension repair.
Figure~\ref{fig:e2e_perf} shows the end-to-end performance comparison.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig6_e2e.pdf}
\caption{\textbf{Context: Why alignment-aware compression matters.} Baseline vs.\ PaLU on Llama-3-8B ($B$=4, $S$=2048). The \textbf{11.5$\times$ decode speedup} comes from KV cache compression~\cite{palu}, orthogonal to dimension repair. \emph{Key point}: Production PaLU enforces 32-multiple alignment internally---if it did not, dimensional collapse would erode these gains. This figure motivates our work: future compression methods must consider alignment to avoid performance cliffs.}
\label{fig:e2e_perf}
\end{figure}

\subsection{Padding Rescue Experiment (P1)}
\label{sec:padding}

Table~\ref{tab:padding} shows the effect of padding $d$=107 to aligned values.

\begin{table}[t]
\centering
\caption{Padding rescue results for SDPA ($d$=107 logical). Measurements: 200 iterations $\times$ 3 trials. Data consistent with Table~\ref{tab:repair_perf}.}
\label{tab:padding}
\small
\begin{tabular}{lrrr}
\toprule
Phys. $d$ & Mem. Ovhd. & Latency (ms$\pm$std) & Speedup \\
\midrule
107 (base) & 0.0\% & 2.06{\scriptsize$\pm$0.06} & 1.00$\times$ \\
112 & 4.7\% & 1.49{\scriptsize$\pm$0.04} & 1.39$\times$ \\
128 & 19.6\% & 1.51{\scriptsize$\pm$0.04} & 1.37$\times$ \\
\bottomrule
\end{tabular}
\end{table}

Padding to 112 achieves 27.8\% speedup with only 4.7\% memory overhead---an excellent tradeoff.

\subsection{GEMM Alignment Impact}

GEMM operations show similar patterns: K=107 achieves 0.089ms latency, while K=112 and K=128 both achieve 0.050ms---a \textbf{44\% improvement} from alignment.

\subsection{Dimension Repair Validation (C4)}
\label{sec:repair_validation}

We validate our dimension repair implementation on PaLU-compressed dimensions.
Figure~\ref{fig:repair_tradeoff} visualizes the speedup vs. memory overhead tradeoff for different strategies.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig5_repair_tradeoff.pdf}
\caption{Speedup vs.\ memory overhead tradeoff for dimension repair. $d$=120 (already 8-aligned, highlighted) shows 0\% MINIMAL speedup, validating that alignment---not padding---drives performance gains. Average ROI: MINIMAL 5.9$\times$ (22\%/3.7\%), OPTIMAL 3.5$\times$ (25\%/7.2\%).}
\label{fig:repair_tradeoff}
\end{figure}

Table~\ref{tab:repair_perf} shows SDPA performance for repaired dimensions.
Memory overhead: MINIMAL 3.72\%, OPTIMAL 7.20\%.

\begin{table}[t]
\centering
\caption{SDPA latency (ms$\pm$std) before and after dimension repair ($B$=4, $S$=2048, $H$=32). Data from independent run vs.\ Tables~\ref{tab:backend}/\ref{tab:padding}; $\sim$6\% variance is within normal GPU measurement variability (\S\ref{sec:phenomenon}).}
\label{tab:repair_perf}
\begin{tabular}{lrrrrr}
\toprule
$d$ & Original (ms) & Minimal (ms) & Optimal (ms) & $\Delta$Min & $\Delta$Opt \\
\midrule
107 & 2.06{\scriptsize$\pm$0.06} & 1.49{\scriptsize$\pm$0.04} & 1.51{\scriptsize$\pm$0.04} & \textbf{+27.8\%} & +27.0\% \\
114 & 2.05{\scriptsize$\pm$0.06} & 1.55{\scriptsize$\pm$0.04} & 1.43{\scriptsize$\pm$0.04} & +24.4\% & \textbf{+30.1\%} \\
117 & 2.05{\scriptsize$\pm$0.06} & 1.57{\scriptsize$\pm$0.04} & 1.43{\scriptsize$\pm$0.04} & +23.7\% & \textbf{+30.2\%} \\
120 & 1.56{\scriptsize$\pm$0.04} & 1.56{\scriptsize$\pm$0.04} & 1.43{\scriptsize$\pm$0.04} & 0.0\% & +8.3\% \\
121 & 1.96{\scriptsize$\pm$0.05} & 1.43{\scriptsize$\pm$0.04} & 1.44{\scriptsize$\pm$0.04} & \textbf{+27.2\%} & +26.6\% \\
125 & 1.98{\scriptsize$\pm$0.05} & 1.44{\scriptsize$\pm$0.04} & 1.44{\scriptsize$\pm$0.04} & \textbf{+27.1\%} & +27.1\% \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Key Findings.}
MINIMAL achieves 23--28\% speedup with 3.72\% overhead (average ROI: speedup\%/overhead\% = 22\%/3.7\% = 5.9$\times$).
$d$=120 validates alignment: 8-aligned (0\% MINIMAL gain) but OPTIMAL pads to 128 for +8.3\%.

\subsection{Framework Validation: Both Positive and Negative Cases}
\label{sec:e2e_validation}

A key contribution of our applicability framework (Table~\ref{tab:applicability}) is its ability to predict repair efficacy \emph{before} implementation. We validate the framework with \emph{two} complementary experiments: (1)~direct SDPA testing where repair should help, and (2)~RAP SVD where it should not.

\paragraph{Positive Validation: Direct SDPA (87\% Speedup).}
To demonstrate that dimension repair provides real benefit when applicable, we test SDPA directly with misaligned dimensions---bypassing architectures that mask the issue.

\textbf{Setup}: We measure SDPA latency for misaligned dimensions ($d \in \{107, 114, 117, 121, 125\}$) vs.\ repaired dimensions ($d \in \{112, 120, 128\}$) across batch sizes $\{1, 4, 8\}$ and sequence lengths $\{512, 1024, 2048\}$ (FlashAttention 2.7.4, FP16, 32 heads).

\textbf{Result}: Table~\ref{tab:direct_sdpa} shows the direct SDPA benchmark achieves \textbf{78--98\% average speedup} (overall mean: \textbf{86.9\%}), with individual measurements ranging from 46\% to 181\% depending on batch size and sequence length.
This confirms that misaligned dimensions cause substantial SDPA performance degradation, and repair recovers this performance.

\begin{table}[t]
\centering
\caption{Direct SDPA validation: speedup from dimension repair. Higher speedups at larger batches due to increased Tensor Core utilization sensitivity.}
\label{tab:direct_sdpa}
\small
\begin{tabular}{llrrrr}
\toprule
Misaligned & Repaired & Avg & Std & Min & Max \\
\midrule
107 & 112 & \textbf{78.5\%} & 29.2\% & 46.3\% & 139.5\% \\
114 & 120 & \textbf{80.2\%} & 29.0\% & 46.9\% & 139.4\% \\
117 & 120 & \textbf{80.7\%} & 28.8\% & 47.0\% & 139.5\% \\
121 & 128 & \textbf{97.0\%} & 38.4\% & 55.1\% & 177.2\% \\
125 & 128 & \textbf{98.1\%} & 39.7\% & 55.4\% & 181.4\% \\
\midrule
\multicolumn{2}{l}{\textbf{Overall}} & \textbf{86.9\%} & 34.5\% & 46.3\% & 181.4\% \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Negative Validation: RAP SVD (--0.8\%).}
For projection-based methods, SDPA operates on \emph{projected} head\_dim (128, already aligned), not the compressed latent space ($d$=102). Our framework predicts \textbf{no benefit}.

\textbf{Result}: RAP SVD on Llama-3-8B shows Prefill --0.8\%, Decode --0.9\% (Table~\ref{tab:rap_e2e})---\emph{exactly as predicted}. Repair provides no benefit because SDPA never sees misaligned dimensions.

\begin{table}[t]
\centering
\caption{RAP SVD E2E validation ($d$=102$\to$104). No speedup validates the ``Projection-based'' row of Table~\ref{tab:applicability}: SDPA operates on aligned head\_dim=128.}
\label{tab:rap_e2e}
\small
\begin{tabular}{lrrr}
\toprule
Phase & Misaligned & Repaired & $\Delta$ \\
\midrule
Prefill (ms) & 290.5 & 292.9 & --0.8\% \\
Decode (tok/s) & 1009 & 1000 & --0.9\% \\
Memory (MB) & 15451 & 15461 & +0.1\% \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Framework Validation Summary.}
Both experiments validate Table~\ref{tab:applicability}:
(1)~Direct SDPA shows \textbf{86.9\% speedup}---repair helps when SDPA sees misaligned dimensions;
(2)~RAP SVD shows \textbf{--0.8\%}---repair doesn't help when projection layers restore aligned head\_dim before SDPA.
Practitioners can consult the framework to predict applicability \emph{before} investing engineering effort.

\subsection{Accuracy Preservation}

Zero-padding guarantees \textbf{bit-exact output preservation}: $y'[0:d_{out}] = y$ exactly.
Unit tests confirm identical outputs (30/30 passed).
WikiText-2 perplexity validation on RAP SVD ($r$=0.8, $d$=102) confirms repair produces \textbf{identical perplexity}: baseline 11.08, RAP SVD 92.39, RAP SVD + repair 92.39 (higher PPL from compression, not repair).

For version-specific notes, see \S\ref{sec:conclusion}.

\subsection{Scope and Limitations}
\label{sec:limitations}

\noindent\fbox{\parbox{0.97\columnwidth}{%
\textbf{L1. Applicability Scope:} The 96.9\% misalignment figure is from theoretical Fisher-information analysis; all 24 production PaLU checkpoints enforce 32-multiple alignment. Our findings apply to: (i) vanilla SVD without constraints, (ii) future methods relaxing alignment for compression.

\smallskip
\textbf{L2. Downstream Tasks:} Zero-padding preserves outputs exactly (perplexity validated on RAP SVD). Comprehensive task evaluation (MMLU, etc.) is future work.

\smallskip
\textbf{L3. Hardware:} All experiments on A100. H100+ generalization is future work (see \S\ref{sec:conclusion}).
}}

\FloatBarrier  % Contain evaluation figures/tables

%% ===========================================
%% 7. RELATED WORK
%% ===========================================
\section{Related Work}
\label{sec:related}

\paragraph{LLM Compression.}
Post-training compression spans multiple paradigms: pruning (SparseGPT~\cite{sparsegpt}), quantization (GPTQ~\cite{gptq}, AWQ~\cite{awq}, QLoRA~\cite{qlora}, LLM.int8()~\cite{llmint8}, SqueezeLLM~\cite{squeezellm}), low-rank adaptation (LoRA~\cite{lora}), and SVD-based decomposition (PaLU~\cite{palu}, SVD-LLM~\cite{svdllm}, CALDERA~\cite{caldera}).
These methods optimize for accuracy-compression trade-offs but largely ignore hardware alignment.
\emph{Which methods produce misaligned dimensions?} SVD-based approaches (PaLU, vanilla SVD, SVD-LLM) can theoretically produce irregular dimensions. However, production checkpoints often enforce alignment internally. GPTQ and AWQ operate on fixed-width groups (typically 128) and do not alter tensor dimensions. Unstructured pruning (SparseGPT) preserves dimensions but creates irregular sparsity.
Our work targets compression methods that \emph{do not} include alignment constraints, filling a gap in the literature.

\paragraph{KV Cache \& Attention Optimization.}
MQA~\cite{mqa}, GQA~\cite{gqa}, and StreamingLLM~\cite{streaminglm} reduce KV cache while preserving standard dimensions.
FlashAttention~\cite{flashattention,flashattention2} is tuned for $\{32, 64, 96, 128, 256\}$, with cliffs for other values.
SVD-based compression produces irregular dimensions that violate these implicit constraints.

\paragraph{Inference Frameworks.}
TensorRT~\cite{tensorrt}, vLLM~\cite{vllm}, TGI~\cite{tgi}, and FlashInfer~\cite{flashinfer} apply runtime optimizations but typically assume aligned dimensions.
Speculative decoding~\cite{speculative_decoding} and multi-head decoding (Medusa~\cite{medusa}) improve throughput orthogonally but inherit dimension constraints from the base model.
vLLM's FlashAttention backend only supports head sizes in $\{64, 80, 96, 112, 128, 256\}$; unsupported dimensions trigger fallback to slower backends~\cite{pytorch_sdpa}.
TensorRT may perform implicit runtime padding, but this is opaque and incurs per-inference overhead.
Our compile-time approach differs: (1) padding is applied once at model export, not per-inference; (2) alignment is explicit and controllable; (3) frameworks can select optimal kernels knowing true dimensions.
FlashDecoding++~\cite{flashdecoding} shows that different GEMM shapes require different dataflows, with up to 50\% performance variance---further evidence that dimension-aware optimization matters.

\paragraph{Dimension Handling Comparison.}
Table~\ref{tab:dim_handling} summarizes how different systems handle head dimensions.
Our compile-time repair makes alignment explicit and avoids runtime overhead.

\begin{table}[t]
\centering
\caption{Head dimension handling across systems. Supported values shown; others may cause fallback or failure.}
\label{tab:dim_handling}
\small
\begin{tabular}{@{}lll@{}}
\toprule
System & Supported \texttt{head\_dim} & Misaligned handling \\
\midrule
FlashAttn-2 & Optimized: 32,64,96,128,256 & Slow path (+30--45\%) \\
vLLM & 64,80,96,112,128,256 & Error/fallback \\
TensorRT & 32,40,64,80,96,104,128... & Runtime padding \\
\midrule
GPTQ/AWQ & Preserves original dims & N/A (no change) \\
PaLU & 32-multiple (enforced) & N/A (aligned) \\
RAP SVD & Any integer & \textbf{Affected} \\
\midrule
\textbf{This work} & Repair to 8/16-multiple & Compile-time fix \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Positioning.}
Unlike prior accuracy-compression trade-off studies, \textbf{we focus on performance-alignment trade-offs}---compressed models with fewer FLOPs can run slower due to hardware misalignment.

%% ===========================================
%% 8. CONCLUSION
%% ===========================================
\section{Conclusion}
\label{sec:conclusion}

We presented a systematic measurement and diagnosis study of \emph{dimensional collapse}---a critical but overlooked problem where LLM compression produces irregular dimensions that degrade GPU performance despite reducing FLOPs.

\textbf{Diagnostic contribution}: We identified and quantified three primary root causes: FlashAttention internal slow paths (+30--45\%), Tensor Core misalignment (58\%), and vectorized load degradation (50\%)---while disconfirming L2 cache waste (5.8\%) as a significant factor.
This diagnosis provides actionable insights for compression method designers.

\textbf{Validated applicability framework}: Our Table~\ref{tab:applicability} correctly predicts when dimension repair helps.
Crucially, it also predicts when repair does \emph{not} help---validated by our RAP SVD experiments showing --0.8\% (no benefit) for projection-based architectures.
When applicable, repair achieves 22--28\% kernel-level speedup with 3.7--7.2\% memory overhead.

\paragraph{H100 Generalization.}
Our experiments focus on A100; H100/H200 validation is future work.
Several factors suggest dimensional collapse likely persists on Hopper GPUs:
(1)~H100's 4th-generation Tensor Cores use m16n8k16 MMA tiles for FP16, requiring $K \mod 16 = 0$ for optimal utilization---the same constraint we identified on A100.
(2)~FlashAttention-3 targets Hopper with optimized kernels for $d \in \{64, 128, 256\}$, indicating dimension-specific optimizations remain important.
(3)~The Tensor Memory Accelerator (TMA) requires 16-byte global alignment, which our 8-alignment strategy satisfies.
Based on these architectural similarities, we predict our dimension repair strategies ($d_{out} \mod 8$ for MINIMAL, $d_{out} \mod 16$ for OPTIMAL) remain applicable on H100.
\emph{Empirical validation is planned future work.}

\paragraph{Software Version Note.}
All results are specific to FlashAttention 2.7.4. Future versions may implement internal alignment handling, potentially reducing the performance gaps we observe.
Our findings remain relevant as guidance for compression method designers and for users of current FlashAttention versions.

\paragraph{Integration with Compression Frameworks.}
Our dimension repair can be integrated as a post-compression pass in frameworks like PaLU, SVD-LLM~\cite{svdllm}, or custom SVD pipelines.
The key is ensuring the Shape Contract is satisfied before SDPA operations:

\emph{For direct compression methods}: Apply repair immediately after rank selection. Given compressed dimension $d_{orig}$, pad to $d_{pad} = \lceil d_{orig}/a \rceil \times a$ where $a=8$ (MINIMAL) or $a=16$ (OPTIMAL). Zero-pad weight matrices and biases; no accuracy loss occurs.

\emph{For projection-based methods}: No repair needed---SDPA operates on projected dimensions. Verify head\_dim alignment at the attention layer, not the latent space.

\emph{Integration checklist}: (1)~Determine architecture type using Table~\ref{tab:applicability}. (2)~If direct compression, apply padding to $W_{kv}$ outputs before attention. (3)~Verify alignment: \texttt{assert d\_out \% 8 == 0}. (4)~Export with aligned dimensions for inference.

\paragraph{Why Projection-Based Methods Don't Benefit.}
Our framework distinguishes two architectural patterns.
In \emph{direct compression} (e.g., vanilla SVD), the compressed head\_dim flows directly to SDPA---misalignment triggers slow paths, and repair recovers performance.
In \emph{projection-based} methods (e.g., RAP SVD), the latent space has irregular dimensions ($d$=102), but projection layers ($W_A$: hidden$\to$latent, $W_B$: latent$\to$head\_dim) restore aligned head\_dim=128 before SDPA.
The misalignment only affects the low-rank projection GEMMs, which have lower relative overhead than attention.
This architectural distinction explains our RAP SVD result (--0.8\%): repair targeted the wrong bottleneck.

%% ===========================================
%% REFERENCES
%% ===========================================
\clearpage
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
