Task: 检查 C1 阶段是否需要更多实验，如果需要，设计并提交

Output:
## 实验设计报告

### 分析结论

经过详细分析，**C1 阶段不需要更多 GPU 实验**。现有数据已经充分覆盖：

#### 已完成的实验
| 实验 | 测量点 | 状态 |
|------|--------|------|
| S1_sdpa_dense_sweep | 162 | ✅ 完成 |
| S2_sdpa_backend_forced | 24 | ✅ 完成 |
| G3_gemm_k_dense | 162 | ✅ 完成 |
| G4_gemm_n_dense | 486 | ✅ 完成 |
| P1_padding_rescue | 9 | ✅ 完成 |
| HET1_hetero_batching | 4 | ✅ 完成 |
| palu_dim_distribution | 2 模型 | ✅ 完成 |

#### C1 关键发现

1. **F1.1**: head_dim=107 导致 SDPA 延迟增加 88% (vs 96)
2. **F1.2**: Math backend 比 Flash 慢 12.6x
3. **F1.4**: **新发现** - PaLU 压缩后 ~97% 的维度不是 8 的倍数
   - Mistral-7B: dims ∈ {114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125}
   - Llama-3-8B: dims ∈ {114, 116, 117, 118, 120, 121, 122, 123, 124, 125}
   - 只有 d=120 是 8 的倍数

### 已执行的操作

1. **补充分析**（非 GPU）：完成 Llama-3-8B PaLU r=0.8 的维度分布分析
2. **状态更新**：
   - `research_state.yaml`: C1_quantified → **true**，C1_quantify.status → **completed**
   - `findings.yaml`: 添加 F1.4, F1.5, F1.6 新发现，添加 I2 洞察，添加 C1_summary

### 下一步建议

C1 阶段已完成，建议进入 **C2_probe** 阶段，重点：
- 2.1 PyTorch backend selection: 验证回退条件
- 2.2 CUDA kernel layer: NCU profiling 分析 Tensor Core 利用率
- 2.3 Hardware layer: L2 cache / bandwidth 分析

**不需要提交新的 Slurm 作业**，因为 C1 数据已充分。


