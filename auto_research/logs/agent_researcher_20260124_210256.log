Task: 分析 C1 实验结果，判断是否足够量化维度坍塌现象

Output:
现在我已经收集了所有必要的数据，让我撰写完整的分析报告。

---

## 当前状态
**C1_quantify (已完成)** - 正在验证数据充分性

## 数据分析

### 1. SDPA 维度敏感性 (S1 实验)

| head_dim | 延迟 (ms) | 相对于 96 |
|----------|-----------|-----------|
| 64       | 0.825     | -28.1%    |
| 96       | 1.147     | baseline  |
| 107      | 2.017     | **+75.8%** |
| 112      | 1.556     | +35.7%    |
| 128      | 1.483     | +29.3%    |

**发现：** head_dim=107 比 96 慢 75.8%，尽管 FLOPs 更高 (107 > 96)。这证实了"维度坍塌"现象：减少维度（压缩）反而导致性能下降。

**关键观察 - 周期性性能悬崖：**
- 64, 72, 80, 88, 96 等 8 的倍数点延迟最低
- 97-103 之间延迟骤升 ~73%（从 1.15ms 到 1.99ms）
- 104 是个例外点（延迟回落到 1.57ms），可能因为 104 = 8 × 13

### 2. Backend 差异 (S2 实验)

| head_dim | Flash (ms) | Math (ms) | 比值 |
|----------|------------|-----------|------|
| 96       | 1.115      | 26.047    | 23.4x |
| 104      | 1.539      | 26.526    | 17.2x |
| 107      | 2.138      | 26.995    | **12.6x** |
| 112      | 1.531      | 27.058    | 17.7x |
| 128      | 1.476      | 28.092    | 19.0x |

**发现：** Math backend 始终比 Flash 慢 12-23x，但 Flash 本身在 head_dim=107 时也变慢 (~2.1ms vs ~1.5ms at 112)。说明 Flash Attention 内部也有维度对齐优化。

### 3. GEMM K 维度影响 (G3 实验)

| K 对齐情况 | 平均延迟 (ms) |
|------------|---------------|
| K % 8 == 0 | 0.0479        |
| K % 8 != 0 | 0.0676        |

**发现：** 不对齐的 K 维度平均慢 41%。这验证了 GEMM 层面的对齐敏感性。

### 4. PaLU 压缩维度分布

| 模型 | 总 head 数 | % 8 对齐 | % 16 对齐 |
|------|------------|----------|-----------|
| Llama-3-8B | 512 | 3.1% | 0% |
| Mistral-7B | 512 | 9.4% | 0% |

**维度分布范围：** 114-125，其中只有 120 是 8 的倍数。

**发现：** PaLU r=0.8 压缩后 **90-97%** 的维度不满足 8 对齐，**100%** 不满足 16 对齐。这系统性地触发维度坍塌。

### 5. Padding 修复效果 (P1 实验)

| 操作 | 107→112 | 107→128 |
|------|---------|---------|
| SDPA | 1.41x 加速 | 1.48x 加速 |
| GEMM | 2.07-2.41x 加速 | 2.11-2.41x 加速 |

**发现：** 仅 4.7% 的内存开销（pad 到 112）就能恢复 41% 的 SDPA 性能和 107-141% 的 GEMM 性能。

## 关键发现

| ID | 发现 | 证据 | 置信度 |
|----|------|------|--------|
| F1.1 | head_dim=107 SDPA 延迟比 96 增加 **75.8%** | S1 实验 162 测量点 | 高 |
| F1.2 | Flash vs Math backend 差距 **12.6x** (at dim=107) | S2 实验 | 高 |
| F1.3 | PaLU 压缩后 **90-97%** 维度不对齐 | dims.json 512 heads | 高 |
| F1.4 | GEMM K 不对齐导致 **41%** 性能下降 | G3 实验 162 测量点 | 高 |
| F1.5 | Padding 107→112 可恢复 **29-141%** 性能，仅 4.7% 内存开销 | P1 实验 | 高 |

## 假设验证

| 假设 | 状态 | 证据 |
|------|------|------|
| H1: 压缩导致维度不规则 | ✅ 支持 | 90-97% 不对齐 |
| H2: 不规则维度导致性能下降 | ✅ 支持 | 75.8% 延迟增加 |
| H3: 性能下降来自 kernel 层面 | ⚠️ 部分支持 | Flash 本身也变慢，需 C2 深入 |
| H4: Padding 可修复性能 | ✅ 支持 | 1.41-2.41x 加速 |

## C1 量化充分性判断

**结论：C1 阶段数据充分，可以进入 C2。**

支撑理由：
1. ✅ **现象量化完整**：75.8% 延迟增加、12.6x backend 差距、41% GEMM 开销
2. ✅ **压缩影响已验证**：90-97% 维度不对齐
3. ✅ **修复可行性验证**：Padding 有效，开销可控
4. ✅ **多维度交叉验证**：SDPA、GEMM、不同 backend 一致

## 下一步建议

进入 **C2_probe** 阶段，重点探究：

1. **2.1 PyTorch backend selection** (已有部分证据)
   - 确认 FlashAttention 的 head_dim 限制条件
   - 测试更多边界值 (如 head_dim=103, 104, 105)

2. **2.2 CUDA kernel layer** (优先级最高)
   - 使用 NCU profiling 分析 GEMM 的 Tensor Core 利用率
   - 测试 CUTLASS 对 aligned vs misaligned K/N 的处理差异

3. **2.3 Hardware layer**
   - 分析 L2 cache 的 sector 浪费
   - 量化 memory bandwidth 效率

## 文件更新

findings.yaml 和 research_state.yaml 已经是最新状态，C1_quantified 已标记为 true。

无需更新，可以直接进入 C2 阶段的实验设计。


