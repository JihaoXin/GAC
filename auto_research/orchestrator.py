#!/usr/bin/env python3
"""
GAC (GPU-Aligned Compression) å…¨è‡ªåŠ¨ç§‘ç ”ä¸»æ§ç³»ç»Ÿ

è¿è¡Œæ–¹å¼:
    # ç ”ç©¶æ¨¡å¼ï¼ˆå®éªŒ + åˆ†æï¼‰
    python auto_research/orchestrator.py --mode research --max-days 3

    # è®ºæ–‡æ¨¡å¼ï¼ˆå®¡ç¨¿ + æ”¹è¿›ï¼‰
    python auto_research/orchestrator.py --mode paper --max-iterations 10

    # åå°è¿è¡Œ
    nohup python auto_research/orchestrator.py --mode paper --max-iterations 20 > auto_research/logs/orchestrator.log 2>&1 &

åŠŸèƒ½:
    ç ”ç©¶æ¨¡å¼ (research):
        1. è¯»å–ç ”ç©¶çŠ¶æ€ï¼Œå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
        2. è°ƒç”¨ä¸“ä¸š Agent æ‰§è¡Œä»»åŠ¡
        3. ç­‰å¾… Slurm ä½œä¸šå®Œæˆ
        4. åˆ†æç»“æœï¼Œæ›´æ–°çŠ¶æ€
        5. å¾ªç¯ç›´åˆ°å®Œæˆæˆ–è¶…æ—¶

    è®ºæ–‡æ¨¡å¼ (paper):
        1. Reviewer Agent å®¡ç¨¿ï¼Œç»™å‡ºè¯„åˆ†å’Œæ”¹è¿›å»ºè®®
        2. Writer Agent æ ¹æ®å»ºè®®æ”¹è¿›è®ºæ–‡
        3. ç¼–è¯‘ LaTeX éªŒè¯
        4. å¾ªç¯ç›´åˆ°è¯„åˆ†è¾¾æ ‡ (>= 8/10) æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
"""

import argparse
import os
import subprocess
import sys
import time
import yaml
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, List
import re

# é¡¹ç›®æ ¹ç›®å½•ï¼ˆå¿…é¡»åœ¨å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ä¹‹å‰è®¾ç½®ï¼‰
PROJECT_DIR = Path(__file__).parent.parent.absolute()
sys.path.insert(0, str(PROJECT_DIR))
os.chdir(PROJECT_DIR)

# æç®€ç‰ˆ Memoryï¼ˆä¸å†ä½¿ç”¨ Event Systemï¼‰
from auto_research.memory import get_memory, SimpleMemory

# é…ç½®
STATE_FILE = PROJECT_DIR / "auto_research" / "state" / "research_state.yaml"
FINDINGS_FILE = PROJECT_DIR / "auto_research" / "state" / "findings.yaml"
PAPER_STATE_FILE = PROJECT_DIR / "auto_research" / "state" / "paper_state.yaml"
PAPER_REQUIREMENTS_FILE = PROJECT_DIR / "auto_research" / "state" / "paper_requirements.yaml"
LOG_DIR = PROJECT_DIR / "auto_research" / "logs"
AGENTS_DIR = PROJECT_DIR / "auto_research" / "agents"
LATEX_DIR = PROJECT_DIR / "Latex"
FIGURES_DIR = LATEX_DIR / "figures"

# ç¡®ä¿ç›®å½•å­˜åœ¨
LOG_DIR.mkdir(parents=True, exist_ok=True)

# è®ºæ–‡å®¡ç¨¿é€šè¿‡é˜ˆå€¼
PAPER_ACCEPT_THRESHOLD = 8  # æ€»ä½“è¯„åˆ† >= 8/10 åˆ™é€šè¿‡

# Checkpoint æ–‡ä»¶
CHECKPOINT_FILE = PROJECT_DIR / "auto_research" / "state" / "checkpoint.yaml"

# Action Plan æ–‡ä»¶ï¼ˆPlanner ç”Ÿæˆï¼‰
ACTION_PLAN_FILE = PROJECT_DIR / "auto_research" / "state" / "action_plan.yaml"


class Orchestrator:
    """ä¸»æ§è°ƒåº¦å™¨"""

    def __init__(self, max_days: float = 3, max_iterations: int = 100, mode: str = "research"):
        self.max_end_time = datetime.now() + timedelta(days=max_days)
        self.max_iterations = max_iterations
        self.iteration = 0
        self.mode = mode  # "research" or "paper"

        # ç»Ÿä¸€æ—¥å¿—æ–‡ä»¶: AutoGAC_<mode>_<date>.log
        self.run_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_file = LOG_DIR / f"AutoGAC_{mode}_{self.run_id}.log"

        # å¯åŠ¨æ—¶æ¸…ç†æ—§æ—¥å¿—
        self._cleanup_old_logs(keep=5)

        # Token ä½¿ç”¨ç»Ÿè®¡
        self.total_input_tokens = 0
        self.total_output_tokens = 0

        # Rate limit çŠ¶æ€ï¼ˆé˜²æ­¢é‡å¤é€šçŸ¥ï¼‰
        self._rate_limit_notified = False

        # æç®€ç‰ˆ Memoryï¼ˆä¸å†ä½¿ç”¨ EventQueueï¼‰
        self.memory = get_memory()
        self._last_score = 0.0  # è¿½è¸ªè¯„åˆ†å˜åŒ–

    def save_checkpoint(self):
        """ä¿å­˜è¿è¡ŒçŠ¶æ€æ£€æŸ¥ç‚¹"""
        checkpoint = {
            "run_id": self.run_id,
            "iteration": self.iteration,
            "mode": self.mode,
            "total_input_tokens": self.total_input_tokens,
            "total_output_tokens": self.total_output_tokens,
            "timestamp": datetime.now().isoformat(),
        }
        with open(CHECKPOINT_FILE, "w") as f:
            yaml.dump(checkpoint, f, default_flow_style=False)
        self.log(f"Checkpoint saved: iteration={self.iteration}", "INFO")

    def load_checkpoint(self) -> dict:
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        if CHECKPOINT_FILE.exists():
            with open(CHECKPOINT_FILE) as f:
                return yaml.safe_load(f) or {}
        return {}

    def resume_from_checkpoint(self):
        """ä»æ£€æŸ¥ç‚¹æ¢å¤"""
        checkpoint = self.load_checkpoint()
        if checkpoint:
            self.iteration = checkpoint.get("iteration", 0)
            self.total_input_tokens = checkpoint.get("total_input_tokens", 0)
            self.total_output_tokens = checkpoint.get("total_output_tokens", 0)
            self.log(f"Resumed from checkpoint: iteration={self.iteration}", "INFO")
            return True
        return False

    def _parse_rate_limit_wait(self, error_msg: str) -> int:
        """ä» rate limit é”™è¯¯ä¿¡æ¯ä¸­è§£æç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰

        æ”¯æŒæ ¼å¼ï¼š
        - "retry after 60 seconds"
        - "retry after 2026-01-25T14:30:00"
        - "reset at 1706188200" (Unix timestamp)
        - "wait 5 minutes"

        Returns:
            ç­‰å¾…ç§’æ•°ï¼Œè§£æå¤±è´¥è¿”å› 300ï¼ˆé»˜è®¤ 5 åˆ†é’Ÿï¼‰
        """
        import re
        from datetime import datetime

        error_lower = error_msg.lower()

        # æ ¼å¼1: "retry after X seconds" æˆ– "wait X seconds"
        match = re.search(r"(?:retry after|wait)\s+(\d+)\s*(?:seconds?|s)", error_lower)
        if match:
            return int(match.group(1))

        # æ ¼å¼2: "X minutes"
        match = re.search(r"(?:retry after|wait)\s+(\d+)\s*(?:minutes?|m)", error_lower)
        if match:
            return int(match.group(1)) * 60

        # æ ¼å¼3: ISO æ—¶é—´æˆ³ "2026-01-25T14:30:00"
        match = re.search(r"(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2})", error_msg)
        if match:
            try:
                reset_time = datetime.fromisoformat(match.group(1))
                wait_seconds = (reset_time - datetime.now()).total_seconds()
                return max(int(wait_seconds), 60)  # è‡³å°‘ç­‰ 60 ç§’
            except ValueError:
                pass

        # æ ¼å¼4: Unix timestamp
        match = re.search(r"reset.*?(\d{10})", error_lower)
        if match:
            try:
                reset_time = datetime.fromtimestamp(int(match.group(1)))
                wait_seconds = (reset_time - datetime.now()).total_seconds()
                return max(int(wait_seconds), 60)
            except (ValueError, OSError):
                pass

        # é»˜è®¤ï¼š5 åˆ†é’Ÿ
        return 300

    def _cleanup_old_logs(self, keep: int = 5):
        """æ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶ï¼Œä¿ç•™æœ€è¿‘çš„ N ä¸ª"""
        # æ¸…ç† AutoGAC_*.log
        autogac_logs = sorted(LOG_DIR.glob("AutoGAC_*.log"), key=lambda f: f.stat().st_mtime, reverse=True)
        for old_log in autogac_logs[keep:]:
            old_log.unlink()

        # æ¸…ç†æ—§çš„ agent_*.log å’Œ orchestrator_*.logï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
        for pattern in ["agent_*.log", "orchestrator_*.log"]:
            old_logs = sorted(LOG_DIR.glob(pattern), key=lambda f: f.stat().st_mtime, reverse=True)
            for old_log in old_logs[keep:]:
                old_log.unlink()

    def _summarize_agent_output(self, agent_type: str, output: str) -> list:
        """ç”Ÿæˆ Agent è¾“å‡ºçš„æ‘˜è¦ï¼Œè¿”å›åˆ—è¡¨æ ¼å¼"""
        if not output or len(output) < 50:
            return []

        summary_lines = []

        if agent_type == "reviewer":
            # ä» latest_review.md è¯»å–å…³é”®ä¿¡æ¯
            review_file = PROJECT_DIR / "auto_research" / "state" / "latest_review.md"
            if review_file.exists():
                content = review_file.read_text()

                # æå–æ€»è¯„åˆ†
                score_match = re.search(r"\*\*Total\*\*.*?\*\*(\d+\.?\d*)/10\*\*", content, re.DOTALL)
                if score_match:
                    summary_lines.append(f"Score: {score_match.group(1)}/10")

                # æå– Rating
                rating_match = re.search(r"\*\*Rating:\s*([^*\n]+)", content)
                if rating_match:
                    summary_lines.append(f"Rating: {rating_match.group(1).strip()}")

                # æå–å„ç»´åº¦åˆ†æ•°ï¼ˆç´§å‡‘æ ¼å¼ï¼‰
                dimensions = [
                    ("Technical Quality", "Tech"),
                    ("Paper Presentation", "Pres"),
                    ("Innovation", "Innov"),
                    ("Writing Quality", "Write"),
                ]
                dim_scores = []
                for eng, chn in dimensions:
                    dim_match = re.search(rf"\|\s*{eng}\s*\|[^|]*\|\s*(\d+)/10", content)
                    if dim_match:
                        dim_scores.append(f"{chn}:{dim_match.group(1)}")
                if dim_scores:
                    summary_lines.append(" | ".join(dim_scores))

                # æå– Major Issues
                major_issues = re.findall(r"### M\d+\.\s*([^\n]+)", content)
                if major_issues:
                    summary_lines.append(f"Major Issues ({len(major_issues)}):")
                    for issue in major_issues[:3]:
                        summary_lines.append(f"  â€¢ {issue.strip()[:40]}")

                # æå– Minor Issues æ•°é‡
                minor_issues = re.findall(r"### m\d+\.\s*([^\n]+)", content)
                if minor_issues:
                    summary_lines.append(f"Minor Issues: {len(minor_issues)}")

        elif agent_type == "writer":
            if "main.tex" in output.lower():
                summary_lines.append("Modified: Latex/main.tex")
            fig_changes = re.findall(r"fig\d+|figure\s*\d+", output, re.IGNORECASE)
            if fig_changes:
                summary_lines.append(f"Figures touched: {len(set(fig_changes))}")

        elif agent_type == "validator":
            if "é€šè¿‡" in output or "pass" in output.lower():
                summary_lines.append("Result: PASS")
            elif "å¤±è´¥" in output or "fail" in output.lower():
                summary_lines.append("Result: FAIL")

        elif agent_type == "experimenter":
            slurm_jobs = re.findall(r"sbatch|srun|slurm", output, re.IGNORECASE)
            if slurm_jobs:
                summary_lines.append(f"Slurm jobs submitted: {len(slurm_jobs)}")

        elif agent_type == "planner":
            # ä» action_plan.yaml è¯»å–
            if ACTION_PLAN_FILE.exists():
                try:
                    with open(ACTION_PLAN_FILE) as f:
                        plan = yaml.safe_load(f) or {}
                    issues = plan.get("issues", [])
                    if issues:
                        exp_count = sum(1 for i in issues if i.get("type") == "EXPERIMENT_REQUIRED")
                        write_count = sum(1 for i in issues if i.get("type") == "WRITING_ONLY")
                        summary_lines.append(f"Issues: {len(issues)} total")
                        summary_lines.append(f"  Experiments: {exp_count}, Writing: {write_count}")
                except Exception:
                    pass

        return summary_lines

    def cleanup_workspace(self):
        """æ¸…ç†å·¥ä½œåŒºï¼ˆLaTeX ä¸´æ—¶æ–‡ä»¶ã€æ—§æ—¥å¿—ç­‰ï¼‰"""
        self.log("æ¸…ç†å·¥ä½œåŒº...", "INFO")
        cleaned = 0

        # 1. æ¸…ç† LaTeX ä¸´æ—¶æ–‡ä»¶
        latex_temp_exts = [".aux", ".log", ".out", ".toc", ".bbl", ".blg", ".fls", ".fdb_latexmk", ".synctex.gz"]
        for ext in latex_temp_exts:
            for f in LATEX_DIR.glob(f"*{ext}"):
                try:
                    f.unlink()
                    cleaned += 1
                except Exception:
                    pass

        # 2. æ¸…ç†æ—§çš„ page_*.pngï¼ˆä¿ç•™æœ€æ–°ä¸€æ‰¹ï¼‰
        page_images = sorted(LATEX_DIR.glob("page_*.png"), key=lambda f: f.stat().st_mtime, reverse=True)
        for img in page_images[10:]:  # ä¿ç•™æœ€å¤š 10 å¼ 
            try:
                img.unlink()
                cleaned += 1
            except Exception:
                pass

        # 3. æ¸…ç† Python ç¼“å­˜
        for cache_dir in PROJECT_DIR.rglob("__pycache__"):
            if cache_dir.is_dir():
                try:
                    import shutil
                    shutil.rmtree(cache_dir)
                    cleaned += 1
                except Exception:
                    pass

        self.log(f"æ¸…ç†å®Œæˆ: åˆ é™¤ {cleaned} ä¸ªä¸´æ—¶æ–‡ä»¶", "INFO")

    def log(self, message: str, level: str = "INFO"):
        """è®°å½•æ—¥å¿—ï¼Œæ”¯æŒçº§åˆ«å’Œå®æ—¶åˆ·æ–°"""
        timestamp = datetime.now().strftime("%H:%M:%S")

        # ç®€æ´æ ¼å¼ï¼šåªæœ‰æ—¶é—´æˆ³ï¼Œæ— çº§åˆ«æ ‡ç­¾ï¼ˆçº§åˆ«é€šè¿‡ç¼©è¿›å’Œå›¾æ ‡ä½“ç°ï¼‰
        if level == "RAW":
            log_message = message
        else:
            log_message = f"[{timestamp}] {message}"

        print(log_message, flush=True)
        with open(self.log_file, "a") as f:
            f.write(log_message + "\n")
            f.flush()

    def log_section(self, title: str, char: str = "â•"):
        """æ‰“å°å¤§èŠ‚æ ‡é¢˜"""
        line = char * 70
        self.log(line, "RAW")
        self.log(f"  {title}", "RAW")
        self.log(line, "RAW")

    def log_phase(self, phase_num: int, total_phases: int, name: str, status: str = "start"):
        """æ‰“å°é˜¶æ®µæ ‡è®°

        Args:
            phase_num: å½“å‰é˜¶æ®µç¼–å·
            total_phases: æ€»é˜¶æ®µæ•°
            name: é˜¶æ®µåç§°
            status: "start" æˆ– "end"
        """
        timestamp = datetime.now().strftime("%H:%M:%S")
        if status == "start":
            self.log("", "RAW")
            self.log(f"â”Œâ”€ PHASE {phase_num}/{total_phases}: {name} " + "â”€" * max(0, 50 - len(name)), "RAW")
            self.log(f"â”‚ [{timestamp}] Starting...", "RAW")
        else:
            self.log(f"â”‚ [{timestamp}] âœ“ Completed", "RAW")
            self.log("â””" + "â”€" * 69, "RAW")

    def log_step(self, message: str, status: str = "info"):
        """æ‰“å°æ­¥éª¤ä¿¡æ¯ï¼ˆåœ¨é˜¶æ®µå†…éƒ¨ä½¿ç”¨ï¼‰

        Args:
            message: æ­¥éª¤æè¿°
            status: "info", "success", "warning", "error", "progress"
        """
        timestamp = datetime.now().strftime("%H:%M:%S")
        icons = {
            "info": " ",
            "success": "âœ“",
            "warning": "âš ",
            "error": "âœ—",
            "progress": "â†’",
        }
        icon = icons.get(status, " ")
        self.log(f"â”‚ [{timestamp}] {icon} {message}", "RAW")

    def log_summary_box(self, title: str, items: list, inside_phase: bool = True):
        """æ‰“å°æ‘˜è¦æ¡†

        Args:
            title: æ‘˜è¦æ ‡é¢˜
            items: æ‘˜è¦é¡¹åˆ—è¡¨ï¼Œæ¯é¡¹ä¸ºå­—ç¬¦ä¸²
            inside_phase: æ˜¯å¦åœ¨é˜¶æ®µå†…éƒ¨ï¼ˆå¸¦ â”‚ å‰ç¼€ï¼‰
        """
        prefix = "â”‚   " if inside_phase else ""
        if inside_phase:
            self.log("â”‚", "RAW")
        self.log(f"{prefix}â”Œâ”€ {title} " + "â”€" * max(0, 50 - len(title)) + "â”", "RAW")
        for item in items:
            lines = item.split("\n") if "\n" in item else [item]
            for line in lines:
                if len(line) > 52:
                    line = line[:49] + "..."
                self.log(f"{prefix}â”‚ {line:<52} â”‚", "RAW")
        self.log(f"{prefix}â””" + "â”€" * 54 + "â”˜", "RAW")

    def load_state(self) -> dict:
        """åŠ è½½ç ”ç©¶çŠ¶æ€"""
        with open(STATE_FILE) as f:
            return yaml.safe_load(f)

    def save_state(self, state: dict):
        """ä¿å­˜ç ”ç©¶çŠ¶æ€"""
        with open(STATE_FILE, "w") as f:
            yaml.dump(state, f, default_flow_style=False, allow_unicode=True)

    def get_current_phase(self, state: dict) -> str:
        """è·å–å½“å‰ç ”ç©¶é˜¶æ®µ"""
        phases = state.get("phases", {})
        for phase_name in ["C1_quantify", "C2_probe", "C3_formulate", "C4_solver", "C5_validation"]:
            phase = phases.get(phase_name, {})
            if phase.get("status") in ["pending", "in_progress"]:
                return phase_name
        return "completed"

    def run_agent(self, agent_type: str, task: str, timeout: int = 1800) -> str:
        """è¿è¡ŒæŒ‡å®šç±»å‹çš„ Agentï¼Œè¾“å‡ºå†™å…¥ç»Ÿä¸€æ—¥å¿—"""
        import json

        prompt_file = AGENTS_DIR / f"{agent_type}.prompt"
        if not prompt_file.exists():
            self.log(f"Agent prompt not found: {prompt_file}", "ERROR")
            return ""

        base_prompt = prompt_file.read_text()

        # è·å–å†å²ä¸Šä¸‹æ–‡ï¼ˆMemory Systemï¼‰
        history_context = self.memory.get_context_for_agent(agent_type)

        full_prompt = f"""{base_prompt}

---

## å½“å‰ä»»åŠ¡

{task}

## è¿­ä»£å†å²ï¼ˆMemoryï¼‰

{history_context if history_context else "è¿™æ˜¯ç¬¬ä¸€æ¬¡è¿­ä»£ï¼Œæ— å†å²è®°å½•ã€‚"}

## ä¸Šä¸‹æ–‡æ–‡ä»¶

è¯·é˜…è¯»ä»¥ä¸‹æ–‡ä»¶è·å–ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼š
- auto_research/state/research_state.yaml - å½“å‰ç ”ç©¶çŠ¶æ€
- auto_research/state/findings.yaml - å·²æœ‰å‘ç°
- report.md - ç ”ç©¶æŠ¥å‘Š
- results/ ç›®å½• - å®éªŒç»“æœ

æ‰§è¡Œä»»åŠ¡å¹¶æ›´æ–°ç›¸åº”æ–‡ä»¶ã€‚
"""

        # æå–ä»»åŠ¡ç®€çŸ­æè¿°ï¼ˆå–ç¬¬ä¸€è¡Œæˆ–å‰50å­—ç¬¦ï¼‰
        task_brief = task.split("\n")[0][:50].strip()
        if len(task.split("\n")[0]) > 50:
            task_brief += "..."
        self.log_step(f"Agent [{agent_type}] â†’ {task_brief}", "progress")

        try:
            # ä½¿ç”¨ --no-session-persistence é¿å… session çŠ¶æ€å¯¼è‡´çš„ tool_use id é‡å¤ bug
            process = subprocess.Popen(
                [
                    "claude", "-p", full_prompt,
                    "--dangerously-skip-permissions",
                    "--no-session-persistence",
                    "--output-format", "text",
                ],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                cwd=PROJECT_DIR,
            )

            start_time = time.time()
            result = ""

            # ä½¿ç”¨ communicate å¹¶è®¾ç½®è¶…æ—¶
            try:
                stdout, stderr = process.communicate(timeout=timeout)
                result = stdout

                # æ£€æŸ¥ stderr ä¸­çš„é”™è¯¯
                if stderr:
                    stderr_lower = stderr.lower()
                    # æ£€æµ‹ rate limit
                    if "rate limit" in stderr_lower or "rate_limit" in stderr_lower:
                        wait_seconds = self._parse_rate_limit_wait(stderr)
                        wait_minutes = wait_seconds / 60
                        self.log(f"æ£€æµ‹åˆ° Rate Limit: éœ€ç­‰å¾… {wait_minutes:.1f} åˆ†é’Ÿ", "WARN")

                        if not self._rate_limit_notified:
                            self._rate_limit_notified = True
                            self.save_checkpoint()
                            self.send_notification(
                                f"Rate Limit - ç­‰å¾… {wait_minutes:.0f} åˆ†é’Ÿ",
                                f"Agent {agent_type} è§¦å‘ rate limitã€‚\n"
                                f"ç­‰å¾…æ—¶é—´: {wait_minutes:.1f} åˆ†é’Ÿ\n"
                                f"é¢„è®¡æ¢å¤: {(datetime.now() + timedelta(seconds=wait_seconds)).strftime('%H:%M:%S')}\n"
                                f"ç³»ç»Ÿå°†è‡ªåŠ¨ç­‰å¾…åæ¢å¤ã€‚",
                                priority="critical"
                            )

                        self.log(f"ç­‰å¾… {wait_minutes:.1f} åˆ†é’Ÿåè‡ªåŠ¨æ¢å¤...", "INFO")
                        time.sleep(wait_seconds + 10)
                        self._rate_limit_notified = False
                    # æ£€æµ‹ API é”™è¯¯
                    elif "error" in stderr_lower and "api" in stderr_lower:
                        self.log(f"  [{agent_type}] API Error: {stderr[:200]}", "AGENT")

            except subprocess.TimeoutExpired:
                process.kill()
                self.log(f"Agent {agent_type} è¶…æ—¶ ({timeout}s)", "WARN")
                stdout, _ = process.communicate()
                result = stdout

            elapsed = int(time.time() - start_time)

            # ç©ºè½¬æ£€æµ‹ï¼šæ‰§è¡Œæ—¶é—´ < 15s ä¸”è¾“å‡ºå¤ªçŸ­ â†’ Agent å¯èƒ½å›  API é—®é¢˜è¿”å›ç©ºç»“æœ
            MIN_AGENT_TIME = 15  # æ­£å¸¸ agent è‡³å°‘éœ€è¦ 15 ç§’
            MIN_RESULT_LEN = 100  # æ­£å¸¸è¾“å‡ºè‡³å°‘ 100 å­—ç¬¦
            if elapsed < MIN_AGENT_TIME and len(result.strip()) < MIN_RESULT_LEN:
                self.log(f"âš ï¸ Agent [{agent_type}] ç©ºè½¬æ£€æµ‹: æ‰§è¡Œä»… {elapsed}sï¼Œè¾“å‡ºä»… {len(result.strip())} å­—ç¬¦", "WARN")
                self.log(f"  å¯èƒ½åŸå› : API rate limit / token è€—å°½ / è¿æ¥å¤±è´¥", "WARN")
                # è®°å½•ç©ºè½¬äº‹ä»¶ï¼Œå¢åŠ ç©ºè½¬è®¡æ•°
                if not hasattr(self, '_agent_empty_count'):
                    self._agent_empty_count = 0
                self._agent_empty_count += 1
                # è¿ç»­ 3 æ¬¡ç©ºè½¬åˆ™æš‚åœç­‰å¾…
                if self._agent_empty_count >= 3:
                    wait_time = 300  # 5 åˆ†é’Ÿ
                    self.log(f"ğŸ›‘ è¿ç»­ {self._agent_empty_count} æ¬¡ Agent ç©ºè½¬ï¼Œæš‚åœ {wait_time}s ç­‰å¾… API æ¢å¤", "ERROR")
                    self.send_notification(
                        "Agent è¿ç»­ç©ºè½¬",
                        f"è¿ç»­ {self._agent_empty_count} æ¬¡ Agent åœ¨ <15s å†…å®Œæˆï¼Œå¯èƒ½ API å—é™ã€‚\næš‚åœ 5 åˆ†é’Ÿç­‰å¾…æ¢å¤ã€‚",
                        priority="critical"
                    )
                    time.sleep(wait_time)
                    self._agent_empty_count = 0
            else:
                # æ­£å¸¸æ‰§è¡Œï¼Œé‡ç½®ç©ºè½¬è®¡æ•°
                if hasattr(self, '_agent_empty_count'):
                    self._agent_empty_count = 0

            self.log_step(f"Agent [{agent_type}] completed ({elapsed}s)", "success")

            # ç”Ÿæˆå¹¶æ‰“å° Agent æ‘˜è¦
            summary_items = self._summarize_agent_output(agent_type, result)
            if summary_items:
                self.log_summary_box(f"{agent_type.upper()} Summary", summary_items)

            return result

        except Exception as e:
            self.log(f"Agent {agent_type} é”™è¯¯: {e}", "ERROR")
            self.send_notification("Agent é”™è¯¯", f"Agent {agent_type} å‘ç”Ÿé”™è¯¯: {e}", priority="critical")
            return ""

    # ========== æ™ºèƒ½è°ƒåº¦ï¼šè®°å¿†ç³»ç»Ÿ ==========

    def record_score_to_memory(self, score: float):
        """è®°å½•åˆ†æ•°åˆ° Memoryï¼ˆæç®€ç‰ˆï¼‰"""
        self.memory.record_score(score)
        self._last_score = score
        self.log(f"Memory: è®°å½•è¯„åˆ† {score}/10", "MEMORY")

    def get_memory_context(self) -> str:
        """è·å– Memory ä¸Šä¸‹æ–‡ï¼ˆåŒ…å« Goal Anchorã€åœæ»è­¦å‘Šã€åˆ†æ•°è¶‹åŠ¿ï¼‰"""
        return self.memory.get_context()

    def wait_for_slurm(self, max_wait_hours: float = 4, job_prefix: str = "GAC_") -> bool:
        """ç­‰å¾… AutoGAC æäº¤çš„ Slurm ä½œä¸šå®Œæˆ

        åªç­‰å¾…ä½œä¸šåç§°ä»¥ job_prefix å¼€å¤´çš„ä½œä¸šï¼ˆé»˜è®¤ "GAC_"ï¼‰ï¼Œ
        å¿½ç•¥å…¶ä»–é¡¹ç›®çš„ä½œä¸šã€‚

        Args:
            max_wait_hours: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆå°æ—¶ï¼‰
            job_prefix: ä½œä¸šåç§°å‰ç¼€ï¼Œåªç­‰å¾…åŒ¹é…çš„ä½œä¸š
        """
        self.log(f"Checking Slurm jobs (prefix: {job_prefix})...")
        max_wait = timedelta(hours=max_wait_hours)
        start_time = datetime.now()

        while datetime.now() - start_time < max_wait:
            try:
                # ä½¿ç”¨ -o æ ¼å¼è·å–ä½œä¸šåç§°: "%j" = job name
                result = subprocess.run(
                    ["squeue", "-u", os.environ.get("USER", "xinj"), "-h", "-o", "%j"],
                    capture_output=True,
                    text=True,
                    timeout=30,
                )

                if not result.stdout.strip():
                    self.log("No Slurm jobs found")
                    return True

                # åªç»Ÿè®¡åŒ¹é…å‰ç¼€çš„ä½œä¸š
                all_jobs = result.stdout.strip().split("\n")
                gac_jobs = [j for j in all_jobs if j.startswith(job_prefix)]
                running_jobs = len(gac_jobs)

                if running_jobs == 0:
                    self.log(f"All {job_prefix}* jobs completed (other jobs: {len(all_jobs)})")
                    return True

                self.log(f"{running_jobs} {job_prefix}* jobs running, waiting 60s...")
                time.sleep(60)

            except Exception as e:
                self.log(f"Error checking Slurm: {e}")
                time.sleep(60)

        self.log(f"Slurm wait timeout after {max_wait_hours} hours")
        return False

    def git_commit(self, message: str, files: list = None):
        """åœ¨å…³é”®èŠ‚ç‚¹è‡ªåŠ¨ git commit

        Args:
            message: commit æ¶ˆæ¯
            files: è¦æäº¤çš„æ–‡ä»¶åˆ—è¡¨ï¼ŒNone è¡¨ç¤ºæ‰€æœ‰æ›´æ”¹
        """
        try:
            # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æ›´æ”¹
            status_result = subprocess.run(
                ["git", "status", "--porcelain"],
                capture_output=True, text=True, cwd=PROJECT_DIR, timeout=30
            )

            if not status_result.stdout.strip():
                self.log("Git: æ²¡æœ‰æ›´æ”¹éœ€è¦æäº¤", "INFO")
                return False

            # æ·»åŠ æ–‡ä»¶
            if files:
                for f in files:
                    subprocess.run(["git", "add", f], cwd=PROJECT_DIR, timeout=30)
            else:
                # æ·»åŠ å…³é”®æ–‡ä»¶ï¼ˆæ’é™¤ä¸´æ—¶æ–‡ä»¶ï¼‰
                key_files = [
                    "Latex/main.tex",
                    "report.md",
                    "auto_research/state/*.yaml",
                    "auto_research/state/*.md",
                ]
                for pattern in key_files:
                    subprocess.run(
                        ["git", "add", pattern],
                        cwd=PROJECT_DIR, timeout=30,
                        capture_output=True  # å¿½ç•¥ä¸å­˜åœ¨çš„æ–‡ä»¶è­¦å‘Š
                    )

            # æäº¤
            commit_msg = f"[AutoGAC] {message}\n\nIteration: {self.iteration}\nScore: {getattr(self, '_last_score', 'N/A')}"
            result = subprocess.run(
                ["git", "commit", "-m", commit_msg],
                capture_output=True, text=True, cwd=PROJECT_DIR, timeout=60
            )

            if result.returncode == 0:
                self.log(f"Git commit: {message}", "INFO")
                return True
            else:
                self.log(f"Git commit å¤±è´¥: {result.stderr[:200]}", "WARN")
                return False

        except Exception as e:
            self.log(f"Git commit é”™è¯¯: {e}", "ERROR")
            return False

    def send_notification(self, subject: str, message: str, priority: str = "normal"):
        """å‘é€é‚®ä»¶é€šçŸ¥

        Args:
            subject: é‚®ä»¶ä¸»é¢˜
            message: é‚®ä»¶å†…å®¹
            priority: ä¼˜å…ˆçº§ ("normal", "critical")
        """
        # å…³é”®è¯è§¦å‘é‚®ä»¶é€šçŸ¥
        critical_keywords = ["error", "failed", "token", "accepted", "completed", "timeout"]
        should_send = priority == "critical" or any(kw in subject.lower() for kw in critical_keywords)

        if not should_send:
            self.log(f"Notification skipped (non-critical): {subject}", "INFO")
            return

        try:
            email = "jihao.xin@kaust.edu.sa"
            # æ·»åŠ çŠ¶æ€æ‘˜è¦
            full_message = f"""{message}

---
AutoGAC Status:
- Run ID: {self.run_id}
- Mode: {self.mode}
- Iteration: {self.iteration}
- Total Tokens: in={self.total_input_tokens:,}, out={self.total_output_tokens:,}
- Log: {self.log_file}
"""
            subprocess.run(
                ["mail", "-s", f"[AutoGAC] {subject}", email],
                input=full_message,
                text=True,
                timeout=30,
            )
            self.log(f"Notification sent: {subject}", "INFO")
        except Exception as e:
            self.log(f"Failed to send notification: {e}", "WARN")

    def compile_latex(self) -> bool:
        """ç¼–è¯‘ LaTeX è®ºæ–‡"""
        self.log("Compiling LaTeX...")
        try:
            # è¿è¡Œ pdflatex + bibtex + pdflatex x2
            for cmd in [
                ["pdflatex", "-interaction=nonstopmode", "main.tex"],
                ["bibtex", "main"],
                ["pdflatex", "-interaction=nonstopmode", "main.tex"],
                ["pdflatex", "-interaction=nonstopmode", "main.tex"],
            ]:
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=120,
                    cwd=LATEX_DIR,
                )
                if result.returncode != 0 and "main.tex" in cmd:
                    self.log(f"LaTeX compilation warning: {result.stderr[:500]}")

            # æ£€æŸ¥ PDF æ˜¯å¦ç”Ÿæˆ
            pdf_path = LATEX_DIR / "main.pdf"
            if pdf_path.exists():
                self.log(f"LaTeX compiled successfully: {pdf_path}")
                return True
            else:
                self.log("LaTeX compilation failed: PDF not generated")
                return False
        except Exception as e:
            self.log(f"LaTeX compilation error: {e}")
            return False

    def load_paper_state(self) -> dict:
        """åŠ è½½è®ºæ–‡å®¡ç¨¿çŠ¶æ€"""
        if PAPER_STATE_FILE.exists():
            with open(PAPER_STATE_FILE) as f:
                return yaml.safe_load(f) or {}
        return {
            "reviews": [],
            "current_score": 0,
            "status": "in_progress",
        }

    def load_paper_requirements(self) -> dict:
        """åŠ è½½è®ºæ–‡éœ€æ±‚é…ç½®"""
        if PAPER_REQUIREMENTS_FILE.exists():
            with open(PAPER_REQUIREMENTS_FILE) as f:
                return yaml.safe_load(f) or {}
        return {}

    def _generate_figures_from_results(self) -> bool:
        """ä»æœ€æ–°å®éªŒç»“æœç”Ÿæˆå›¾è¡¨å¹¶å¤åˆ¶åˆ°è®ºæ–‡ç›®å½•"""
        self.log(">>> ä»å®éªŒç»“æœç”Ÿæˆæ–°å›¾è¡¨...", "FIGURES")
        try:
            import glob
            import shutil

            # æ‰¾æœ€æ–°çš„å®éªŒç»“æœç›®å½•
            result_dirs = []
            for exp_type in ["llm", "perplexity_validation", "gemm", "sdpa"]:
                pattern = str(PROJECT_DIR / f"results/{exp_type}/*")
                dirs = glob.glob(pattern)
                result_dirs.extend(dirs)

            if not result_dirs:
                self.log("  æ²¡æœ‰æ‰¾åˆ°æ–°å®éªŒç»“æœ", "FIGURES")
                self.memory.mark_experiment_empty()  # æ ‡è®°å®éªŒç©ºè½¬
                return False

            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„
            result_dirs.sort(key=lambda x: Path(x).stat().st_mtime if Path(x).is_dir() else 0, reverse=True)
            latest_result = Path(result_dirs[0])

            self.log(f"  æœ€æ–°ç»“æœ: {latest_result}", "FIGURES")

            # å°è¯•è¿è¡Œå¯¹åº”çš„å›¾è¡¨ç”Ÿæˆè„šæœ¬
            if "llm" in str(latest_result):
                cmd = f"python -m scripts.plot_llm_results {latest_result.parent}"
            else:
                cmd = f"python -m scripts.plot_results {latest_result}"

            self.log(f"  è¿è¡Œ: {cmd}", "FIGURES")
            result = subprocess.run(
                ["bash", "-c", f"source ~/.bashrc && mamba activate gac && {cmd}"],
                capture_output=True, text=True, timeout=300, cwd=PROJECT_DIR
            )

            if result.returncode != 0:
                self.log(f"  å›¾è¡¨ç”Ÿæˆè­¦å‘Š: {result.stderr[:200]}", "WARN")

            # å¤åˆ¶æ–°ç”Ÿæˆçš„å›¾è¡¨åˆ° Latex/figures/
            plots_dir = latest_result / "plots"
            if plots_dir.exists():
                for pdf in plots_dir.glob("*.pdf"):
                    dest = FIGURES_DIR / pdf.name
                    shutil.copy(pdf, dest)
                    self.log(f"  å¤åˆ¶å›¾è¡¨: {pdf.name} -> Latex/figures/", "FIGURES")
                self.memory.clear_experiment_empty()  # å®éªŒæˆåŠŸäº§å‡ºç»“æœ

            return True

        except Exception as e:
            self.log(f"  å›¾è¡¨ç”Ÿæˆé”™è¯¯: {e}", "ERROR")
            return False

    def generate_figures(self) -> bool:
        """è¿è¡Œå›¾è¡¨ç”Ÿæˆè„šæœ¬"""
        self.log("Generating paper figures...", "INFO")
        try:
            # ç¡®ä¿ figures ç›®å½•å­˜åœ¨
            FIGURES_DIR.mkdir(parents=True, exist_ok=True)

            result = subprocess.run(
                ["bash", "-c", "source ~/.bashrc && mamba activate gac && python scripts/create_paper_figures.py"],
                capture_output=True,
                text=True,
                timeout=300,
                cwd=PROJECT_DIR,
            )

            if result.returncode == 0:
                self.log("Figure generation completed successfully", "INFO")
                # ç”Ÿæˆåè¿›è¡Œè´¨é‡é¢„æ£€
                self._precheck_figure_quality()
                return True
            else:
                self.log(f"Figure generation warning: {result.stderr[:500]}", "WARN")
                return True  # ç»§ç»­ï¼Œå³ä½¿æœ‰è­¦å‘Š
        except Exception as e:
            self.log(f"Figure generation error: {e}", "ERROR")
            return False

    def _precheck_figure_quality(self):
        """å›¾è¡¨è´¨é‡é¢„æ£€ - åœ¨ Reviewer ä¹‹å‰ä¸»åŠ¨å‘ç°é—®é¢˜

        æ£€æŸ¥é¡¹ï¼š
        1. å›¾è¡¨æ¯”ä¾‹æ˜¯å¦è¿‡äºæ‰å¹³
        2. åˆ†è¾¨ç‡æ˜¯å¦è¶³å¤Ÿ
        3. PDF ç‰ˆæœ¬æ˜¯å¦å­˜åœ¨
        """
        self.log(">>> å›¾è¡¨è´¨é‡é¢„æ£€...", "PRECHECK")
        try:
            from PIL import Image

            issues = []
            for fig_path in sorted(FIGURES_DIR.glob("fig*.png")):
                img = Image.open(fig_path)
                width, height = img.size
                aspect_ratio = height / width

                # æ£€æŸ¥ 1: æ¯”ä¾‹æ˜¯å¦è¿‡äºæ‰å¹³ (é«˜åº¦åº” >= å®½åº¦ * 0.35)
                if aspect_ratio < 0.35:
                    issues.append(f"  âš ï¸ {fig_path.name}: æ¯”ä¾‹è¿‡æ‰ ({aspect_ratio:.2f})ï¼Œå»ºè®®é«˜åº¦ â‰¥ å®½åº¦Ã—0.4")

                # æ£€æŸ¥ 2: åˆ†è¾¨ç‡æ˜¯å¦è¶³å¤Ÿ
                if width < 600:
                    issues.append(f"  âš ï¸ {fig_path.name}: å®½åº¦è¿‡å° ({width}px)ï¼Œå»ºè®® â‰¥ 800px")

                img.close()

            # æ£€æŸ¥ PDF ç‰ˆæœ¬æ˜¯å¦å­˜åœ¨
            for png_path in FIGURES_DIR.glob("fig*.png"):
                pdf_path = png_path.with_suffix('.pdf')
                if not pdf_path.exists():
                    issues.append(f"  âš ï¸ {png_path.stem}: ç¼ºå°‘ PDF ç‰ˆæœ¬")

            if issues:
                self.log("å‘ç°å›¾è¡¨è´¨é‡é—®é¢˜:", "PRECHECK")
                for issue in issues:
                    self.log(issue, "PRECHECK")
                self.log("å»ºè®®ä¿®æ”¹ scripts/create_paper_figures.py å¹¶é‡æ–°ç”Ÿæˆ", "PRECHECK")
            else:
                self.log("å›¾è¡¨è´¨é‡æ£€æŸ¥é€šè¿‡ âœ“", "PRECHECK")

        except ImportError:
            self.log("Pillow æœªå®‰è£…ï¼Œè·³è¿‡å›¾è¡¨é¢„æ£€", "WARN")
        except Exception as e:
            self.log(f"å›¾è¡¨é¢„æ£€é”™è¯¯: {e}", "WARN")

    def pdf_to_images(self) -> list:
        """å°† PDF è½¬æ¢ä¸ºå›¾åƒç”¨äºè§†è§‰å®¡æ ¸"""
        self.log("Converting PDF to images for visual review...", "INFO")
        try:
            result = subprocess.run(
                ["bash", "-c", "source ~/.bashrc && mamba activate gac && python scripts/pdf_to_images.py Latex/main.pdf --dpi 150"],
                capture_output=True,
                text=True,
                timeout=120,
                cwd=PROJECT_DIR,
            )

            if result.returncode == 0:
                # è·å–ç”Ÿæˆçš„å›¾åƒåˆ—è¡¨
                images = list(LATEX_DIR.glob("page_*.png"))
                self.log(f"Generated {len(images)} page images", "INFO")
                return [str(img) for img in sorted(images)]
            else:
                self.log(f"PDF to images warning: {result.stderr[:200]}", "WARN")
                return []
        except Exception as e:
            self.log(f"PDF to images error: {e}", "ERROR")
            return []

    def save_paper_state(self, state: dict):
        """ä¿å­˜è®ºæ–‡å®¡ç¨¿çŠ¶æ€"""
        with open(PAPER_STATE_FILE, "w") as f:
            yaml.dump(state, f, default_flow_style=False, allow_unicode=True)

    def _load_action_plan(self) -> dict:
        """åŠ è½½ Planner ç”Ÿæˆçš„ action plan

        åŒ…å«å®¹é”™å¤„ç†ï¼šPlanner ç”Ÿæˆçš„ YAML å¯èƒ½åŒ…å« LaTeX å‘½ä»¤ï¼ˆå¦‚ \\subsectionï¼‰ï¼Œ
        åœ¨åŒå¼•å·å†…ä¼šè¢« YAML è§£æå™¨å½“ä½œéæ³• escape sequenceã€‚
        ä¿®å¤æ–¹æ³•ï¼šå°†åŒå¼•å·å€¼è½¬æ¢ä¸ºå•å¼•å·ï¼ˆå•å¼•å·å†…åæ–œæ ä¸ä¼šè¢«è½¬ä¹‰ï¼‰ã€‚
        """
        if ACTION_PLAN_FILE.exists():
            try:
                with open(ACTION_PLAN_FILE) as f:
                    return yaml.safe_load(f) or {}
            except yaml.YAMLError as e:
                self.log(f"YAML è§£æé”™è¯¯ï¼Œå°è¯•ä¿®å¤ LaTeX escape: {e}", "WARN")
                try:
                    raw = ACTION_PLAN_FILE.read_text()
                    import re
                    # å°†åŒ…å«åæ–œæ çš„åŒå¼•å·å€¼è½¬æ¢ä¸ºå•å¼•å·
                    # åŒ¹é…: "...\...." â†’ '...\....'
                    def fix_dquoted(match):
                        content = match.group(1)
                        if '\\' in content:
                            # åŒå¼•å·å†…æœ‰åæ–œæ ï¼Œè½¬ä¸ºå•å¼•å·
                            # å…ˆå¤„ç†å•å¼•å·è½¬ä¹‰ï¼ˆå•å¼•å·å†…ç”¨ '' è¡¨ç¤º 'ï¼‰
                            content = content.replace("'", "''")
                            return "'" + content + "'"
                        return match.group(0)

                    # åŒ¹é…åŒå¼•å·å­—ç¬¦ä¸²ï¼ˆéè´ªå©ªï¼Œä¸è·¨è¡Œï¼‰
                    fixed = re.sub(r'"([^"\n]*)"', fix_dquoted, raw)
                    ACTION_PLAN_FILE.write_text(fixed)
                    result = yaml.safe_load(fixed) or {}
                    self.log("YAML ä¿®å¤æˆåŠŸï¼ˆLaTeX escape â†’ å•å¼•å·ï¼‰", "INFO")
                    return result
                except Exception as e2:
                    self.log(f"YAML ä¿®å¤å¤±è´¥: {e2}ï¼Œè¿”å›ç©º plan", "ERROR")
                    return {"issues": []}
        return {"issues": []}

    def _save_action_plan(self, action_plan: dict):
        """ä¿å­˜ action plan"""
        with open(ACTION_PLAN_FILE, "w") as f:
            yaml.dump(action_plan, f, default_flow_style=False, allow_unicode=True)

    def _load_findings_summary(self) -> str:
        """åŠ è½½ findings.yaml çš„æ‘˜è¦"""
        if FINDINGS_FILE.exists():
            with open(FINDINGS_FILE) as f:
                findings = yaml.safe_load(f) or {}
            # è¿”å›æ‘˜è¦ï¼ˆå‰ 500 å­—ç¬¦ï¼‰
            return yaml.dump(findings, allow_unicode=True)[:500]
        return "æš‚æ—  findings"

    def _wait_for_slurm_jobs(self, max_wait_hours: float = 2) -> bool:
        """ç­‰å¾… Slurm ä½œä¸šå®Œæˆï¼ˆå†…éƒ¨ä½¿ç”¨çš„ç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        return self.wait_for_slurm(max_wait_hours=max_wait_hours)

    def parse_review_score(self, review_output: str) -> float:
        """ä»å®¡ç¨¿è¾“å‡ºä¸­è§£ææ€»ä½“è¯„åˆ†"""
        # æ”¯æŒå¤šç§æ ¼å¼ï¼š
        # 1. "æ€»ä½“è¯„åˆ†: 7/10" æˆ– "Overall Score: 7/10"
        # 2. "| **Total** | 100% | - | **7.5/10** |" (è¡¨æ ¼æ ¼å¼)
        # 3. ä»»æ„ "X/10" æˆ– "X.X/10"
        patterns = [
            r"æ€»ä½“è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)/10",
            r"Overall Score[ï¼š:]\s*(\d+\.?\d*)/10",
            r"æ€»åˆ†[ï¼š:]\s*(\d+\.?\d*)/10",
            r"\*\*Total\*\*.*?\*\*(\d+\.?\d*)/10\*\*",  # è¡¨æ ¼ Markdown æ ¼å¼
            r"\|\s*Total\s*\|.*?(\d+\.?\d*)/10",       # ç®€åŒ–è¡¨æ ¼æ ¼å¼
        ]
        for pattern in patterns:
            match = re.search(pattern, review_output, re.IGNORECASE | re.DOTALL)
            if match:
                score = float(match.group(1))
                self.log(f"è§£æåˆ°è¯„åˆ†: {score}/10")
                return score

        # å…œåº•ï¼šä» latest_review.md æ–‡ä»¶è¯»å–
        review_file = PROJECT_DIR / "auto_research" / "state" / "latest_review.md"
        if review_file.exists():
            content = review_file.read_text()
            for pattern in patterns:
                match = re.search(pattern, content, re.IGNORECASE | re.DOTALL)
                if match:
                    score = float(match.group(1))
                    self.log(f"ä» latest_review.md è§£æåˆ°è¯„åˆ†: {score}/10")
                    return score

        self.log("è­¦å‘Š: æœªèƒ½è§£æåˆ°è¯„åˆ†ï¼Œè¿”å› 0")
        return 0.0

    def extract_issue_ids(self) -> List[str]:
        """ä» latest_review.md æå–æ‰€æœ‰ issue IDs

        Returns:
            List of issue IDs like ["M1", "M2", "m1", "m2"]
        """
        review_file = PROJECT_DIR / "auto_research" / "state" / "latest_review.md"
        if not review_file.exists():
            return []

        content = review_file.read_text()

        # åŒ¹é… issue ID æ¨¡å¼ï¼š
        # - M1, M2, M3 (Major)
        # - m1, m2, m3 (minor)
        # - ä¹Ÿæ”¯æŒ "### M1." æˆ– "**M1:**" ç­‰æ ¼å¼
        issue_pattern = r'\b([Mm]\d+)\b'
        matches = re.findall(issue_pattern, content)

        # å»é‡å¹¶æ ‡å‡†åŒ–
        unique_issues = list(set(matches))
        self.log(f"æå–åˆ° {len(unique_issues)} ä¸ª issues: {unique_issues}")
        return unique_issues

    def _check_needs_experiment(self, review_output: str) -> bool:
        """åˆ†æå®¡ç¨¿æ„è§ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è¡¥å……å®éªŒ

        æ£€æµ‹å…³é”®è¯ï¼š
        - "éœ€è¦è¡¥å……å®éªŒ" / "add experiment"
        - "ç¼ºå°‘æ•°æ®" / "missing data"
        - "éªŒè¯ä¸è¶³" / "insufficient validation"
        - "å»ºè®®å¢åŠ " / "suggest adding"
        """
        # ä¹Ÿæ£€æŸ¥ latest_review.md æ–‡ä»¶
        review_file = PROJECT_DIR / "auto_research" / "state" / "latest_review.md"
        content = review_output
        if review_file.exists():
            content += "\n" + review_file.read_text()

        # å®éªŒç›¸å…³å…³é”®è¯
        experiment_keywords = [
            r"éœ€è¦.*å®éªŒ",
            r"è¡¥å…….*å®éªŒ",
            r"ç¼ºå°‘.*æ•°æ®",
            r"éªŒè¯ä¸è¶³",
            r"å»ºè®®.*å¢åŠ .*å®éªŒ",
            r"add.*experiment",
            r"missing.*data",
            r"insufficient.*validation",
            r"suggest.*adding.*experiment",
            r"need.*more.*evidence",
            r"require.*additional.*test",
        ]

        for pattern in experiment_keywords:
            if re.search(pattern, content, re.IGNORECASE):
                self.log(f"æ£€æµ‹åˆ°å®éªŒéœ€æ±‚å…³é”®è¯: {pattern}", "INFO")
                return True

        return False

    def _check_needs_literature_search(self, review_output: str) -> tuple:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦æ–‡çŒ®è°ƒç ”

        Returns:
            (needs_search: bool, search_topics: list)
        """
        # è¯»å– latest_review.md
        review_file = PROJECT_DIR / "auto_research" / "state" / "latest_review.md"
        content = review_output
        if review_file.exists():
            content += "\n" + review_file.read_text()

        search_topics = []

        # æ£€æµ‹ related work ç›¸å…³é—®é¢˜
        related_work_keywords = [
            r"related work.*insufficient",
            r"related work.*missing",
            r"ç¼ºå°‘.*ç›¸å…³å·¥ä½œ",
            r"should cite",
            r"compare with.*other",
            r"missing.*comparison",
            r"prior work",
            r"existing.*method",
        ]
        for pattern in related_work_keywords:
            if re.search(pattern, content, re.IGNORECASE):
                search_topics.append("related_work")
                break

        # æ£€æµ‹æŠ€æœ¯éªŒè¯éœ€æ±‚
        tech_keywords = [
            r"verify.*claim",
            r"documentation.*support",
            r"FlashAttention.*behavior",
            r"Tensor Core.*requirement",
            r"æŠ€æœ¯.*éªŒè¯",
        ]
        for pattern in tech_keywords:
            if re.search(pattern, content, re.IGNORECASE):
                search_topics.append("technical_verification")
                break

        # æ£€æµ‹ç«äº‰æ–¹æ³•å¯¹æ¯”éœ€æ±‚
        comparison_keywords = [
            r"compare.*baseline",
            r"other.*compression",
            r"alternative.*method",
            r"state.of.the.art",
            r"SOTA",
        ]
        for pattern in comparison_keywords:
            if re.search(pattern, content, re.IGNORECASE):
                search_topics.append("competitive_analysis")
                break

        return len(search_topics) > 0, search_topics

    def run_literature_search(self, topics: list) -> str:
        """è¿è¡Œæ–‡çŒ®è°ƒç ”

        Args:
            topics: éœ€è¦è°ƒç ”çš„ä¸»é¢˜åˆ—è¡¨
        """
        self.log_step(f"Literature search: {topics}", "progress")

        topic_prompts = {
            "related_work": """
æœç´¢ä¸ä»¥ä¸‹ä¸»é¢˜ç›¸å…³çš„è®ºæ–‡å’Œå·¥ä½œï¼š
1. LLM å‹ç¼©æ–¹æ³• (SVD, low-rank, quantization)
2. FlashAttention å’Œ GPU attention ä¼˜åŒ–
3. Tensor Core å¯¹é½å’Œ CUDA ä¼˜åŒ–

æœç´¢è¯å»ºè®®ï¼š
- "LLM compression dimension alignment"
- "FlashAttention head dimension requirements"
- "Tensor Core alignment performance"
- "PaLU low-rank compression"

æ‰¾åˆ°ç›¸å…³è®ºæ–‡åï¼Œæå–ï¼š
- è®ºæ–‡æ ‡é¢˜ã€ä½œè€…ã€å¹´ä»½
- æ ¸å¿ƒè´¡çŒ®
- ä¸æˆ‘ä»¬å·¥ä½œçš„å…³ç³»
- æ˜¯å¦éœ€è¦åœ¨ Related Work ä¸­å¼•ç”¨
""",
            "technical_verification": """
æŸ¥æ‰¾æŠ€æœ¯æ–‡æ¡£éªŒè¯ä»¥ä¸‹å£°æ˜ï¼š
1. FlashAttention å¯¹ head_dim çš„è¦æ±‚
2. PyTorch SDPA backend é€‰æ‹©é€»è¾‘
3. Tensor Core mma æŒ‡ä»¤çš„å¯¹é½è¦æ±‚

æŸ¥æ‰¾èµ„æºï¼š
- FlashAttention GitHub repo å’Œæ–‡æ¡£
- PyTorch å®˜æ–¹æ–‡æ¡£
- NVIDIA CUDA ç¼–ç¨‹æŒ‡å—

æå–å…·ä½“çš„æŠ€æœ¯è§„æ ¼å’Œä»£ç å¼•ç”¨ã€‚
""",
            "competitive_analysis": """
æœç´¢ç«äº‰æ–¹æ³•çš„æ€§èƒ½æ•°æ®ï¼š
1. å…¶ä»– LLM å‹ç¼©æ–¹æ³•çš„ latency/memory tradeoff
2. æ¨ç†æ¡†æ¶ï¼ˆvLLM, TensorRT-LLMï¼‰çš„ä¼˜åŒ–ç­–ç•¥
3. å…¶ä»–ç»´åº¦å¯¹é½è§£å†³æ–¹æ¡ˆ

æ‰¾åˆ°åæå–ï¼š
- æ–¹æ³•åç§°
- æ€§èƒ½æ•°æ®ï¼ˆlatency, memory, accuracyï¼‰
- ä¸æˆ‘ä»¬æ–¹æ³•çš„å¯¹æ¯”ç‚¹
"""
        }

        combined_prompt = "è¯·è¿›è¡Œä»¥ä¸‹æ–‡çŒ®è°ƒç ”ï¼š\n\n"
        for topic in topics:
            if topic in topic_prompts:
                combined_prompt += f"## {topic}\n{topic_prompts[topic]}\n\n"

        combined_prompt += """
å®Œæˆåï¼Œå°†é‡è¦å‘ç°ä¿å­˜åˆ° auto_research/state/literature.yaml
æ ¼å¼ï¼š
```yaml
searches:
  - date: "YYYY-MM-DD"
    topic: "topic_name"
    findings:
      - title: "è®ºæ–‡/æ–‡æ¡£æ ‡é¢˜"
        source: "URL æˆ–å¼•ç”¨"
        relevance: "ä¸æˆ‘ä»¬å·¥ä½œçš„å…³ç³»"
        key_points: ["è¦ç‚¹1", "è¦ç‚¹2"]
    action_items:
      - "éœ€è¦å¼•ç”¨çš„è®ºæ–‡"
      - "éœ€è¦å¯¹æ¯”çš„æ–¹æ³•"
```
"""
        return self.run_agent("literature", combined_prompt, timeout=1800)

    def run_planner_cycle(self, review_output: str) -> bool:
        """Planner é©±åŠ¨çš„è¿­ä»£å¾ªç¯

        æµç¨‹:
        1. æ£€æŸ¥æ˜¯å¦éœ€è¦æ–‡çŒ®è°ƒç ”
        2. Planner åˆ†æ reviewï¼Œç”Ÿæˆ action_plan.yaml
        3. æ‰§è¡Œæ‰€æœ‰å®éªŒç±»ä»»åŠ¡ï¼ˆinner loopï¼‰
        4. æ‰€æœ‰å®éªŒå®Œæˆåï¼Œæ‰§è¡Œå†™ä½œä»»åŠ¡

        Args:
            review_output: Reviewer çš„è¾“å‡º

        Returns:
            True å¦‚æœæˆåŠŸå®Œæˆ
        """
        import json

        # Step 0: æ£€æŸ¥æ˜¯å¦éœ€è¦æ–‡çŒ®è°ƒç ”
        needs_lit, lit_topics = self._check_needs_literature_search(review_output)
        if needs_lit:
            self.log_step(f"Literature search needed: {lit_topics}", "progress")
            self.run_literature_search(lit_topics)

        # Step 1: Planner åˆ†æ reviewï¼Œç”Ÿæˆ action plan
        self.log_step("Planner analyzing review...", "progress")
        findings_summary = self._load_findings_summary()

        # è·å–ç­–ç•¥å‡çº§è¦æ±‚ï¼ˆå…³é”®ï¼ï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œæ²¡æœ‰ issue descriptionsï¼Œæ‰€ä»¥ç”¨ç©º dict
        # å®é™…åˆ†ç±»ä¼šåœ¨ plan æ‰§è¡ŒååŸºäº action_plan çš„ title/description è¿›è¡Œ
        escalations = self.memory.get_strategy_escalation()
        escalation_prompt = ""
        if escalations:
            escalation_prompt = "\n## ğŸš¨ ç­–ç•¥å‡çº§å»ºè®®\n\n"
            escalation_prompt += "**æ³¨æ„**: ç³»ç»Ÿä¼šæ ¹æ®é—®é¢˜ç±»å‹æ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦å‡çº§\n"
            escalation_prompt += "- å±•ç¤º/æ’ç‰ˆé—®é¢˜ï¼šä¼˜å…ˆç”¨ WRITING_ONLY æˆ– FIGURE_CODE_REQUIRED\n"
            escalation_prompt += "- æŠ€æœ¯/æ•°æ®é—®é¢˜ï¼šå¯èƒ½éœ€è¦ EXPERIMENT_REQUIRED\n\n"
            for issue_id, info in escalations.items():
                count = info["count"]
                banned = info["banned_methods"]
                required = info["required_escalation"]
                issue_type = info.get("issue_type", "unknown")
                escalation_prompt += f"**{issue_id}** (é‡å¤ {count} æ¬¡, ç±»å‹: {issue_type}):\n"
                if banned:
                    escalation_prompt += f"  - âš ï¸ å·²å°è¯•å¤šæ¬¡: {', '.join(banned)}\n"
                if required:
                    escalation_prompt += f"  - ğŸ’¡ å»ºè®®: **{required}**\n"
                escalation_prompt += "\n"

        planner_output = self.run_agent("planner", f"""
åˆ†æä»¥ä¸‹å®¡ç¨¿æ„è§ï¼Œç”Ÿæˆ action_plan.yamlã€‚
{escalation_prompt}
## å®¡ç¨¿æ„è§æ‘˜è¦
è¯·è¯»å–å®Œæ•´å®¡ç¨¿æŠ¥å‘Šï¼šauto_research/state/latest_review.md

## å½“å‰ Findings æ‘˜è¦
{findings_summary}

## ä»»åŠ¡
1. è¯†åˆ«æ‰€æœ‰ Major Issues (M1, M2, ...) å’Œ Minor Issues (m1, m2, ...)
2. å¯¹æ¯ä¸ª issue åˆ†ç±»ï¼šEXPERIMENT_REQUIRED, FIGURE_CODE_REQUIRED, æˆ– WRITING_ONLY
3. âš ï¸ æ£€æŸ¥ç­–ç•¥å‡çº§è¦æ±‚ï¼Œç¡®ä¿ä¸ä½¿ç”¨ç¦ç”¨çš„æ–¹æ³•
4. ä¸ºæ¯ä¸ª issue ç”Ÿæˆå…·ä½“çš„ action åˆ—è¡¨
5. å°†ç»“æœå†™å…¥ auto_research/state/action_plan.yaml

æ³¨æ„ï¼š
- EXPERIMENT_REQUIRED: éœ€è¦è·‘ GPU å®éªŒï¼ˆå¦‚æ·»åŠ  perplexity æµ‹é‡ã€è¡¥å…… benchmarkï¼‰
- FIGURE_CODE_REQUIRED: éœ€è¦ä¿®æ”¹ Python ç»˜å›¾è„šæœ¬å¹¶é‡æ–°è¿è¡Œ
- WRITING_ONLY: åªéœ€ä¿®æ”¹ LaTeX æ–‡å­—
""", timeout=1200)

        # Step 2: åŠ è½½ç”Ÿæˆçš„ action plan
        action_plan = self._load_action_plan()
        issues = action_plan.get("issues", [])

        if not issues:
            self.log_step("Planner generated no issues, skipping", "warning")
            return False

        exp_count = sum(1 for i in issues if i.get("type") == "EXPERIMENT_REQUIRED")
        lit_count = sum(1 for i in issues if i.get("type") == "LITERATURE_REQUIRED")
        fig_count = sum(1 for i in issues if i.get("type") == "FIGURE_CODE_REQUIRED")
        write_count = sum(1 for i in issues if i.get("type") == "WRITING_ONLY")
        self.log_step(f"Plan: {len(issues)} issues (exp:{exp_count}, lit:{lit_count}, fig:{fig_count}, write:{write_count})", "success")

        # è®°å½•æ¯ä¸ª issue ä½¿ç”¨çš„ä¿®å¤æ–¹æ³•ï¼ˆç”¨äºè‡ªæ£€å’Œç­–ç•¥å‡çº§ï¼‰
        violations = []
        for issue in issues:
            issue_id = issue.get("id", "")
            issue_type = issue.get("type", "")
            # è·å– issue æè¿°ç”¨äºåˆ†ç±»ï¼ˆä¼˜å…ˆ titleï¼Œå…¶æ¬¡ descriptionï¼‰
            issue_desc = issue.get("title", "") or issue.get("description", "")
            if issue_id and issue_type:
                self.memory.record_repair_method(issue_id, issue_type)
                # æ£€æŸ¥æ˜¯å¦è¿åäº†ç­–ç•¥å‡çº§è¦æ±‚ï¼ˆä¼ å…¥æè¿°ä»¥ä¾¿æ­£ç¡®åˆ†ç±»ï¼‰
                banned = self.memory.get_banned_methods(issue_id, issue_desc)
                if issue_type in banned:
                    violations.append((issue_id, issue_type, banned, issue_desc))
                    self.log(f"ğŸš« è¿è§„: {issue_id} ä½¿ç”¨äº†è¢«ç¦ç”¨çš„æ–¹æ³• {issue_type}ï¼", "ERROR")

        # å¦‚æœæœ‰è¿è§„ï¼Œæä¾›å»ºè®®ä½†ä¸å¼ºåˆ¶é‡æ–°è§„åˆ’ï¼ˆè®©ç³»ç»Ÿè‡ªå·±åˆ¤æ–­ï¼‰
        if violations:
            self.log("ğŸ’¡ æ£€æµ‹åˆ°å¯èƒ½çš„ç­–ç•¥æ”¹è¿›å»ºè®®", "WARNING")
            for v in violations:
                issue_id, issue_type, banned, issue_desc = v
                # æ£€æŸ¥é—®é¢˜ç±»å‹
                pres_type = self.memory.classify_issue_type(issue_desc)
                if pres_type == "presentation":
                    self.log(f"  {issue_id}: å±•ç¤ºé—®é¢˜ï¼Œ{issue_type} å¯èƒ½åˆé€‚ï¼Œç»§ç»­æ‰§è¡Œ", "INFO")
                else:
                    self.log(f"  {issue_id}: æŠ€æœ¯é—®é¢˜ï¼Œå»ºè®®æ¢ç”¨ {[m for m in ['FIGURE_CODE_REQUIRED', 'EXPERIMENT_REQUIRED'] if m not in banned]}", "WARNING")

        # Step 2.5: æ‰§è¡Œæ–‡çŒ®è°ƒç ”ä»»åŠ¡
        for issue in issues:
            if issue.get("type") == "LITERATURE_REQUIRED" and issue.get("status", "pending") == "pending":
                self.log_step(f"Literature: {issue.get('id')} - {issue.get('title', '')[:30]}", "progress")
                issue["status"] = "in_progress"
                self._save_action_plan(action_plan)

                # æå–æœç´¢ä¸»é¢˜
                description = issue.get("description", "")
                search_task = f"""
æ–‡çŒ®è°ƒç ”ä»»åŠ¡: {issue.get('title')}

æè¿°: {description}

è¯·ï¼š
1. ä½¿ç”¨ WebSearch æœç´¢ç›¸å…³è®ºæ–‡å’Œæ–‡æ¡£
2. ä½¿ç”¨ WebFetch è·å–å…·ä½“å†…å®¹
3. æå–å…³é”®ä¿¡æ¯
4. æ›´æ–° auto_research/state/literature.yaml
"""
                self.run_agent("literature", search_task, timeout=1800)
                issue["status"] = "completed"
                self._save_action_plan(action_plan)

        # Step 3: æ‰§è¡Œå®éªŒç±»ä»»åŠ¡ï¼ˆinner loopï¼‰
        for issue in issues:
            if issue.get("type") == "EXPERIMENT_REQUIRED" and issue.get("status", "pending") == "pending":
                self.log_step(f"Experiment: {issue.get('id')} - {issue.get('title', '')[:30]}", "progress")
                self._run_experiment_inner_loop(issue, action_plan)

        # Step 4: æ£€æŸ¥æ‰€æœ‰å®éªŒæ˜¯å¦å®Œæˆ
        all_experiments_done = all(
            issue.get("status") in ["completed", "failed", "skipped"]
            for issue in issues
            if issue.get("type") == "EXPERIMENT_REQUIRED"
        )

        if all_experiments_done:
            self.log_step("Experiments done, starting writing phase...", "progress")
            self._run_writing_phase(action_plan)
            return True

        self.log_step("Some experiments incomplete", "warning")
        return False

    def _run_experiment_inner_loop(self, issue: dict, action_plan: dict):
        """æ‰§è¡Œå•ä¸ªå®éªŒç±» issue çš„å†…éƒ¨è¿­ä»£

        æµç¨‹:
        1. Experimenter è®¾è®¡å¹¶è¿è¡Œå®éªŒ
        2. ç­‰å¾… Slurm ä½œä¸šå®Œæˆ
        3. Researcher åˆ†æç»“æœ
        4. Planner è¯„ä¼°æ˜¯å¦æ»¡æ„
        5. å¦‚æœä¸æ»¡æ„ä¸”æœªè¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé‡å¤

        Args:
            issue: issue å­—å…¸
            action_plan: å®Œæ•´çš„ action planï¼ˆç”¨äºä¿å­˜çŠ¶æ€ï¼‰
        """
        import json

        max_loops = issue.get("max_inner_loops", 3)
        issue["inner_loop_count"] = issue.get("inner_loop_count", 0)
        issue["status"] = "in_progress"
        self._save_action_plan(action_plan)

        # è·å– experimenter ä»»åŠ¡
        exp_task = issue.get("description", issue.get("title", "æœªçŸ¥ä»»åŠ¡"))
        actions = issue.get("actions", [])
        if actions:
            for action in actions:
                if action.get("agent") == "experimenter":
                    exp_task = action.get("task", exp_task)
                    break

        while issue["inner_loop_count"] < max_loops:
            issue["inner_loop_count"] += 1
            loop_num = issue["inner_loop_count"]
            self.log_step(f"Inner Loop {loop_num}/{max_loops}: {issue.get('id')}", "progress")

            # 1. Experimenter è®¾è®¡å¹¶è¿è¡Œå®éªŒ
            exp_output = self.run_agent("experimenter", f"""
ä»»åŠ¡: {exp_task}

Issue èƒŒæ™¯:
- ID: {issue.get('id')}
- æ ‡é¢˜: {issue.get('title')}
- æè¿°: {issue.get('description', 'N/A')}

è¿™æ˜¯ Inner Loop ç¬¬ {loop_num} æ¬¡å°è¯•ï¼ˆæœ€å¤š {max_loops} æ¬¡ï¼‰ã€‚
è¯·è®¾è®¡å¹¶æäº¤å®éªŒï¼Œä½¿ç”¨ Slurm è¿è¡Œ GPU ä»»åŠ¡ã€‚
""", timeout=1800)

            # 2. ç­‰å¾… Slurm ä½œä¸šå®Œæˆ
            self.log_step("Waiting for Slurm jobs...", "info")
            self._wait_for_slurm_jobs(max_wait_hours=2)

            # 3. Researcher åˆ†æç»“æœ
            research_output = self.run_agent("researcher", f"""
åˆ†æå®éªŒç»“æœï¼Œåˆ¤æ–­æ˜¯å¦æ»¡è¶³å®¡ç¨¿è¦æ±‚ã€‚

Issue: {issue.get('id')} - {issue.get('title')}
ä»»åŠ¡: {exp_task}

è¯·æ£€æŸ¥:
1. å®éªŒæ˜¯å¦æˆåŠŸå®Œæˆï¼ˆæ—  OOMã€æ— é”™è¯¯ï¼‰
2. ç»“æœæ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
3. æ•°æ®æ˜¯å¦æ”¯æŒè®ºæ–‡è®ºç‚¹
4. æ›´æ–° findings.yaml è®°å½•æ–°å‘ç°

ç»™å‡ºæ˜ç¡®ç»“è®ºï¼šå®éªŒæ˜¯å¦æ»¡è¶³è¦æ±‚ã€‚
""", timeout=1200)

            # 4. Planner è¯„ä¼°æ˜¯å¦æ»¡æ„
            eval_output = self.run_agent("planner", f"""
è¯„ä¼° Inner Loop ç»“æœï¼Œåˆ¤æ–­æ˜¯å¦å¯ä»¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µã€‚

## Issue ä¿¡æ¯
- ID: {issue.get('id')}
- æ ‡é¢˜: {issue.get('title')}
- å½“å‰å°è¯•: {loop_num}/{max_loops}

## Experimenter è¾“å‡ºæ‘˜è¦
{exp_output[:800] if exp_output else 'æ— è¾“å‡º'}

## Researcher åˆ†ææ‘˜è¦
{research_output[:800] if research_output else 'æ— è¾“å‡º'}

## è¯·åˆ¤æ–­
è¾“å‡º JSON æ ¼å¼çš„è¯„ä¼°ç»“æœï¼ˆåªè¾“å‡º JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼‰ï¼š

```json
{{
  "satisfied": true/false,
  "experiment_success": true/false,
  "supports_paper": true/false,
  "reason": "åˆ¤æ–­ç†ç”±",
  "next_action": "proceed_to_writing" | "retry_experiment" | "mark_failed"
}}
```
""", timeout=600)

            # è§£æ Planner è¯„ä¼°ç»“æœ
            satisfied = False
            try:
                # å°è¯•ä»è¾“å‡ºä¸­æå– JSON
                json_match = re.search(r'\{[^{}]*"satisfied"[^{}]*\}', eval_output, re.DOTALL)
                if json_match:
                    eval_json = json.loads(json_match.group())
                    satisfied = eval_json.get("satisfied", False)
                else:
                    # ç®€å•çš„å…³é”®è¯åˆ¤æ–­
                    satisfied = '"satisfied": true' in eval_output.lower() or '"satisfied":true' in eval_output.lower()
            except json.JSONDecodeError:
                satisfied = "satisfied.*true" in eval_output.lower() or "å®éªŒæˆåŠŸ" in eval_output

            if satisfied:
                issue["status"] = "completed"
                self._save_action_plan(action_plan)
                self.log_step(f"Issue {issue.get('id')} completed", "success")
                self._generate_figures_from_results()
                return

            self.log_step(f"Loop {loop_num} not satisfied, retrying...", "warning")

        # è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°
        issue["status"] = "failed"
        issue["failure_reason"] = f"Exceeded max loops {max_loops}"
        self._save_action_plan(action_plan)
        self.log_step(f"{issue.get('id')} failed after {max_loops} attempts", "error")

    def _run_writing_phase(self, action_plan: dict):
        """æ‰§è¡Œå†™ä½œé˜¶æ®µ

        å°†æ‰€æœ‰ WRITING_ONLY ä»»åŠ¡å’Œå·²å®Œæˆå®éªŒçš„å†™ä½œä»»åŠ¡äº¤ç»™ Writer å¤„ç†ã€‚

        Args:
            action_plan: action plan å­—å…¸
        """
        issues = action_plan.get("issues", [])

        # æ”¶é›†æ‰€æœ‰å†™ä½œä»»åŠ¡
        writing_tasks = []

        for issue in issues:
            if issue.get("type") == "WRITING_ONLY":
                writing_tasks.append({
                    "id": issue.get("id"),
                    "title": issue.get("title"),
                    "description": issue.get("description", ""),
                    "actions": issue.get("actions", []),
                })
                issue["status"] = "in_progress"
            elif issue.get("type") == "EXPERIMENT_REQUIRED" and issue.get("status") == "completed":
                # å®éªŒå®Œæˆåçš„å†™ä½œä»»åŠ¡
                for action in issue.get("actions", []):
                    if action.get("agent") == "writer":
                        writing_tasks.append({
                            "id": issue.get("id"),
                            "title": f"æ•´åˆ {issue.get('title')} å®éªŒç»“æœ",
                            "description": action.get("task", ""),
                            "actions": [action],
                        })
            elif issue.get("type") == "LITERATURE_REQUIRED" and issue.get("status") == "completed":
                # æ–‡çŒ®è°ƒç ”å®Œæˆåçš„å†™ä½œä»»åŠ¡ï¼ˆå°†æ–‡çŒ®å†…å®¹å†™å…¥ LaTeXï¼‰
                for action in issue.get("actions", []):
                    if action.get("agent") == "writer":
                        writing_tasks.append({
                            "id": issue.get("id"),
                            "title": f"æ ¹æ®æ–‡çŒ®è°ƒç ”æ›´æ–° {issue.get('title')}",
                            "description": action.get("task", ""),
                            "actions": [action],
                        })
                        self.log(f"  ğŸ“š æ·»åŠ æ–‡çŒ®å†™ä½œä»»åŠ¡: {issue.get('id')} - å°†æ–‡çŒ®å†…å®¹å†™å…¥ LaTeX", "INFO")

        if not writing_tasks:
            self.log_step("No writing tasks to execute", "info")
            return

        # æ„å»ºå†™ä½œä»»åŠ¡æè¿°
        task_list = []
        for i, task in enumerate(writing_tasks, 1):
            task_list.append(f"""
### ä»»åŠ¡ {i}: {task['id']} - {task['title']}
{task['description']}
""")

        # åˆ†ç±»ä»»åŠ¡ï¼šFIGURE_CODE_REQUIRED å’Œ WRITING_ONLY
        figure_tasks = [i for i in issues if i.get("type") == "FIGURE_CODE_REQUIRED"]
        pure_writing_tasks = [i for i in issues if i.get("type") == "WRITING_ONLY"]

        # ========== é˜¶æ®µ 1: å¤„ç† FIGURE_CODE_REQUIRED ä»»åŠ¡ ==========
        if figure_tasks:
            self.log_step(f"Processing {len(figure_tasks)} FIGURE_CODE_REQUIRED tasks (modifying Python code)", "progress")

            # æ„å»ºè¯¦ç»†çš„ Python ä»£ç ä¿®æ”¹æŒ‡ä»¤
            figure_instructions = []
            for task in figure_tasks:
                task_id = task.get("id", "")
                task_title = task.get("title", "")
                task_desc = task.get("description", "")
                actions = task.get("actions", [])

                # æå–å…³é”®ä¿¡æ¯
                target_file = "scripts/create_paper_figures.py"
                target_function = ""
                modification = task_desc

                for action in actions:
                    if "target_file" in action:
                        target_file = action["target_file"]
                    if "target_function" in action:
                        target_function = action["target_function"]
                    if "modification" in action:
                        modification = action["modification"]

                figure_instructions.append(f"""
### {task_id}: {task_title}

**CRITICAL**: ä½ å¿…é¡»ä¿®æ”¹ Python ä»£ç ï¼Œä¸æ˜¯ LaTeXï¼

**Target file**: {target_file}
**Target function**: {target_function if target_function else "è§ä»»åŠ¡æè¿°"}
**Modification needed**: {modification}

**Detailed task**:
{task_desc}

**Action steps**:
1. ä½¿ç”¨ Read å·¥å…·é˜…è¯» {target_file}
2. æ‰¾åˆ°å¯¹åº”çš„å‡½æ•°ï¼ˆå¦‚ fig3_palu_distributionï¼‰
3. ä½¿ç”¨ Edit å·¥å…·ä¿®æ”¹ matplotlib å‚æ•°ï¼ˆfigsize, fontsize, tight_layout ç­‰ï¼‰
4. ç¡®è®¤ä¿®æ”¹åçš„ä»£ç è¯­æ³•æ­£ç¡®
5. ä¸è¦è¿è¡Œè„šæœ¬ï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨è¿è¡Œï¼‰
""")

            # è°ƒç”¨ writer agent ä¿®æ”¹ Python ä»£ç 
            self.run_agent("writer", f"""
## CRITICAL TASK: ä¿®æ”¹ Python ç»˜å›¾è„šæœ¬ï¼ˆä¸æ˜¯ LaTeXï¼ï¼‰

ä½ æ”¶åˆ°äº† {len(figure_tasks)} ä¸ª FIGURE_CODE_REQUIRED ä»»åŠ¡ã€‚
è¿™äº›ä»»åŠ¡éœ€è¦ä¿®æ”¹ **Python ä»£ç **ï¼Œè€Œä¸æ˜¯ LaTeX æ–‡ä»¶ï¼

{''.join(figure_instructions)}

## å·¥å…·ä½¿ç”¨è¦æ±‚
- å¿…é¡»ä½¿ç”¨ Read å·¥å…·è¯»å– scripts/create_paper_figures.py
- å¿…é¡»ä½¿ç”¨ Edit å·¥å…·ä¿®æ”¹ä»£ç 
- ä¸è¦ä½¿ç”¨ Bash è¿è¡Œè„šæœ¬ï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨è¿è¡Œï¼‰

## å‡½æ•°åå‚è€ƒ
- Figure 1: fig1_overview
- Figure 2: fig2_sdpa_latency
- Figure 3: fig3_palu_distribution
- Figure 4: fig4_root_cause
- Figure 5: fig5_repair_tradeoff
- Figure 6: fig6_e2e_performance

## éªŒè¯
ä¿®æ”¹å®Œæˆåï¼Œç¡®ä¿ï¼š
1. Python è¯­æ³•æ­£ç¡®ï¼ˆæ²¡æœ‰ç¼©è¿›é”™è¯¯ã€æ‹¬å·åŒ¹é…ï¼‰
2. matplotlib å‚æ•°åˆç†ï¼ˆfigsize, fontsize, etc.ï¼‰
3. æ–‡ä»¶è·¯å¾„æ­£ç¡®ï¼ˆLatex/figures/*.pdfï¼‰
""", timeout=1800)

            # éªŒè¯ Python è„šæœ¬æ˜¯å¦çœŸçš„è¢«ä¿®æ”¹
            self.log_step("Verifying Python code changes...", "progress")
            try:
                result = subprocess.run(
                    ["git", "diff", "--name-only", "scripts/create_paper_figures.py"],
                    capture_output=True,
                    text=True,
                    cwd=PROJECT_DIR
                )
                if "scripts/create_paper_figures.py" in result.stdout:
                    self.log_step("Python code modified successfully", "success")
                else:
                    self.log_step("WARNING: FIGURE_CODE_REQUIRED task but Python not modified!", "error")
                    self.log("This indicates Writer agent did not correctly execute the task.", "WARN")
            except Exception as e:
                self.log(f"Verification failed: {e}", "WARN")

            # è¿è¡Œä¿®æ”¹åçš„è„šæœ¬ç”Ÿæˆæ–°å›¾è¡¨
            self.log_step("Regenerating figures with modified code...", "progress")
            try:
                result = subprocess.run(
                    ["python", "scripts/create_paper_figures.py"],
                    capture_output=True,
                    text=True,
                    timeout=120,
                    cwd=PROJECT_DIR
                )
                if result.returncode == 0:
                    self.log_step("Figures regenerated successfully", "success")
                    # é‡æ–°ç¼–è¯‘ LaTeX ä»¥æ›´æ–° PDF
                    self.compile_latex()
                else:
                    self.log_step(f"Figure generation failed: {result.stderr[:200]}", "error")
            except Exception as e:
                self.log_step(f"Figure generation error: {e}", "error")

        # ========== é˜¶æ®µ 2: å¤„ç†å†™ä½œä»»åŠ¡ï¼ˆåˆ†ä¼˜å…ˆçº§æ‰§è¡Œï¼‰==========
        # å°†å†™ä½œä»»åŠ¡åˆ†ä¸ºé«˜ä¼˜å…ˆçº§ï¼ˆé€ä¸ªæ‰§è¡Œï¼‰å’Œæ™®é€šï¼ˆå¯æ‰¹é‡ï¼‰
        high_priority_tasks = []
        batch_tasks = []

        for task in writing_tasks:
            task_id = task.get("id", "")
            title = (task.get("title", "") or "").lower()
            # Major issues æˆ– Related Work/Literature ä»»åŠ¡ â†’ å•ç‹¬æ‰§è¡Œ
            if (task_id.startswith("M") or
                "related work" in title or "æ–‡çŒ®" in title or
                "citation" in title or "å¼•ç”¨" in title):
                high_priority_tasks.append(task)
            else:
                batch_tasks.append(task)

        self.log_step(f"Writing tasks: {len(high_priority_tasks)} high-priority (individual), {len(batch_tasks)} batch", "progress")

        # é˜¶æ®µ 2A: é€ä¸ªæ‰§è¡Œé«˜ä¼˜å…ˆçº§ä»»åŠ¡
        for task in high_priority_tasks:
            self.log_step(f"Writing (individual): {task['id']} - {task.get('title', '')[:40]}", "progress")

            # è·å–æ–‡çŒ®ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœæœ‰ï¼‰
            literature_context = self._get_literature_context_for_task(task)

            self.run_agent("writer", f"""
ä½ åªæœ‰ä¸€ä¸ªä»»åŠ¡è¦å®Œæˆã€‚è¯·è®¤çœŸã€å½»åº•åœ°å®Œæˆå®ƒã€‚

## ä»»åŠ¡: {task['id']} - {task.get('title', '')}
{task.get('description', '')}
{literature_context}

## è¦æ±‚
1. ä»”ç»†é˜…è¯» Latex/main.tex ä¸­çš„ç›¸å…³éƒ¨åˆ†
2. åšå‡ºå®è´¨æ€§ä¿®æ”¹ï¼ˆä¸æ˜¯å°è°ƒæ•´ï¼‰
3. ç¡®ä¿ä¿®æ”¹å LaTeX è¯­æ³•æ­£ç¡®
4. ä¿æŒè®ºæ–‡æ ¸å¿ƒè´¡çŒ®ä¸å˜
5. å‚è€ƒ paper_example/ ç›®å½•çš„é«˜è´¨é‡è®ºæ–‡é£æ ¼

## å‚è€ƒæ–‡ä»¶
- auto_research/state/latest_review.md - å®¡ç¨¿æŠ¥å‘Š
- auto_research/state/literature.yaml - æ–‡çŒ®è°ƒç ”ç»“æœ
- Latex/references.bib - å‚è€ƒæ–‡çŒ®åº“
""", timeout=1800)

            # éªŒè¯: æ£€æŸ¥ main.tex æ˜¯å¦çœŸçš„è¢«ä¿®æ”¹
            try:
                diff_output = subprocess.run(
                    ["git", "diff", "--stat", "Latex/main.tex"],
                    capture_output=True, text=True, cwd=PROJECT_DIR
                ).stdout
                if diff_output.strip():
                    self.log_step(f"  âœ“ {task['id']}: changes detected", "success")
                else:
                    self.log_step(f"  âœ— {task['id']}: No changes detected! Task may have failed.", "error")
            except Exception as e:
                self.log(f"  Verification error: {e}", "WARN")

        # é˜¶æ®µ 2B: æ‰¹é‡æ‰§è¡Œæ™®é€šä»»åŠ¡
        if batch_tasks:
            self.log_step(f"Processing {len(batch_tasks)} batch writing tasks", "progress")

            task_list = []
            for idx, task in enumerate(batch_tasks, 1):
                task_list.append(f"""
### Task {idx}: {task.get('id', '')} - {task.get('title', '')}
{task.get('description', '')}
""")

            self.run_agent("writer", f"""
è¯·æ ¹æ®ä»¥ä¸‹å®¡ç¨¿ä¿®æ”¹ä»»åŠ¡ï¼Œæ›´æ–°è®ºæ–‡ Latex/main.texã€‚

## ä¿®æ”¹ä»»åŠ¡åˆ—è¡¨

{''.join(task_list)}

## æ³¨æ„äº‹é¡¹
1. æ¯ä¸ªä¿®æ”¹åç¡®ä¿ LaTeX è¯­æ³•æ­£ç¡®
2. ä¿æŒè®ºæ–‡æ ¸å¿ƒè´¡çŒ®ä¸å˜
3. å‚è€ƒ paper_example/ ç›®å½•çš„é«˜è´¨é‡è®ºæ–‡é£æ ¼

## å‚è€ƒæ–‡ä»¶
- auto_research/state/latest_review.md - å®¡ç¨¿æŠ¥å‘Š
- auto_research/state/action_plan.yaml - å®Œæ•´ä»»åŠ¡åˆ—è¡¨
""", timeout=3600)

        # å†™ä½œè´¨é‡éªŒè¯: æ£€æŸ¥æ€»ä¿®æ”¹é‡
        try:
            diff_result = subprocess.run(
                ["git", "diff", "--numstat", "Latex/main.tex"],
                capture_output=True, text=True, cwd=PROJECT_DIR
            )
            total_added = 0
            if diff_result.stdout.strip():
                for line in diff_result.stdout.strip().split("\n"):
                    parts = line.split("\t")
                    if len(parts) >= 2 and parts[0].isdigit():
                        total_added += int(parts[0])

            if total_added < 5:
                self.log(f"âš ï¸ å†™ä½œé˜¶æ®µä»…æ·»åŠ  {total_added} è¡Œï¼Œä¿®æ”¹å¯èƒ½ä¸å……åˆ†", "WARN")
            else:
                self.log(f"å†™ä½œé˜¶æ®µå…±æ·»åŠ  {total_added} è¡Œ", "INFO")
        except Exception as e:
            self.log(f"å†™ä½œè´¨é‡éªŒè¯å¤±è´¥: {e}", "WARN")

        # æ ‡è®°å†™ä½œä»»åŠ¡å®Œæˆ
        for issue in issues:
            if issue.get("type") in ["WRITING_ONLY", "FIGURE_CODE_REQUIRED"]:
                issue["status"] = "completed"

        self._save_action_plan(action_plan)
        self.log_step("Writing phase completed", "success")

    def _get_literature_context_for_task(self, task: dict) -> str:
        """è¯»å– literature.yamlï¼Œæå–ä¸å½“å‰ä»»åŠ¡ç›¸å…³çš„æ–‡çŒ®å†…å®¹

        Args:
            task: å†™ä½œä»»åŠ¡å­—å…¸

        Returns:
            æ ¼å¼åŒ–çš„æ–‡çŒ®ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼Œå¦‚æœæ— æ–‡çŒ®åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        lit_file = PROJECT_DIR / "auto_research" / "state" / "literature.yaml"
        if not lit_file.exists():
            return ""

        try:
            lit_data = yaml.safe_load(lit_file.read_text()) or {}

            # å°è¯•å¤šç§å¯èƒ½çš„ keyï¼ˆliterature agent è¾“å‡ºæ ¼å¼å¯èƒ½ä¸åŒï¼‰
            entries = lit_data.get("entries", [])
            if not entries:
                entries = lit_data.get("papers", [])
            if not entries:
                entries = lit_data.get("references", [])
            if not entries and isinstance(lit_data, list):
                entries = lit_data

            if not entries:
                # å¦‚æœæ˜¯åµŒå¥—ç»“æ„ï¼Œå°è¯•æå–æ‰€æœ‰æ–‡çŒ®
                for key, val in lit_data.items():
                    if isinstance(val, list) and len(val) > 0:
                        entries = val
                        break

            if not entries:
                return ""

            # æ„å»ºæ–‡çŒ®ä¸Šä¸‹æ–‡
            lines = ["\n## å¯ç”¨çš„æ–‡çŒ®èµ„æºï¼ˆæ¥è‡ª Literature Agentï¼‰\n"]
            for entry in entries[:20]:  # æœ€å¤š 20 æ¡
                if isinstance(entry, dict):
                    title = entry.get("title", "")
                    bibtex_key = entry.get("bibtex_key", entry.get("key", entry.get("cite_key", "")))
                    summary = entry.get("summary", entry.get("abstract", ""))
                    if title:
                        cite_str = f" (cite: \\cite{{{bibtex_key}}})" if bibtex_key else ""
                        lines.append(f"- **{title}**{cite_str}")
                        if summary:
                            lines.append(f"  {summary[:200]}")
                elif isinstance(entry, str):
                    lines.append(f"- {entry}")

            if len(lines) > 1:
                lines.append("\nè¯·åœ¨ Related Work å’Œå…¶ä»–é€‚å½“ä½ç½®å¼•ç”¨è¿™äº›æ–‡çŒ®ã€‚")
                lines.append("BibTeX æ¡ç›®å·²åœ¨ Latex/references.bib ä¸­ï¼Œè¯·ä½¿ç”¨ \\cite{} å¼•ç”¨ã€‚")
                return "\n".join(lines)
            return ""
        except Exception:
            return ""

    def _get_bottleneck(self) -> str:
        """ä» latest_review.md æå–ç“¶é¢ˆç»´åº¦

        Returns:
            ç“¶é¢ˆç»´åº¦åç§°ï¼Œå¦‚ "Technical Quality", "Presentation" ç­‰
            å¦‚æœæ— æ³•æå–ï¼Œè¿”å› "Unknown"
        """
        review_path = Path("auto_research/state/latest_review.md")
        if not review_path.exists():
            return "Unknown"

        try:
            content = review_path.read_text()
            # åŒ¹é… "ä¸»è¦ç“¶é¢ˆç»´åº¦: Technical Quality" æˆ– "ä¸»è¦ç“¶é¢ˆ: Technical"
            import re
            patterns = [
                r"ä¸»è¦ç“¶é¢ˆç»´åº¦[ï¼š:]\s*([^\n]+)",
                r"ä¸»è¦ç“¶é¢ˆ[ï¼š:]\s*([^\n]+)",
                r"\*\*ä¸»è¦ç“¶é¢ˆ\*\*[ï¼š:]\s*([^\n]+)",
            ]
            for pattern in patterns:
                match = re.search(pattern, content)
                if match:
                    bottleneck = match.group(1).strip()
                    # æ¸…ç†å¯èƒ½çš„ markdown æ ¼å¼
                    bottleneck = bottleneck.replace("*", "").strip()
                    return bottleneck
        except Exception as e:
            self.log(f"Failed to extract bottleneck: {e}", "WARN")

        return "Unknown"

    def decide_next_action(self) -> str:
        """æ ¹æ®å½“å‰çŠ¶æ€åŠ¨æ€å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨

        è¿™æ˜¯æ™ºèƒ½è¿­ä»£çš„æ ¸å¿ƒï¼šä¸å†æ˜¯å›ºå®šæµç¨‹ï¼Œè€Œæ˜¯æ ¹æ®çŠ¶æ€é€‰æ‹©ã€‚

        Returns:
            action: "RUN_EXPERIMENTS" | "TRIGGER_EXPERIMENT_PLANNING" |
                    "SELF_REPAIR" | "NORMAL_ITERATION"
        """
        # è¯»å–çŠ¶æ€
        score = self.memory.scores[-1] if self.memory.scores else 0
        action_plan = self._load_action_plan()
        bottleneck = self._get_bottleneck()

        self.log(f"Decision context: score={score}, bottleneck={bottleneck}, "
                 f"stagnation={self.memory.stagnation_count}", "DECISION")

        # æ£€æŸ¥æ˜¯å¦æœ‰å¾…æ‰§è¡Œçš„å®éªŒ
        issues = action_plan.get("issues", [])
        pending_experiments = [
            t for t in issues
            if t.get("type") == "EXPERIMENT_REQUIRED"
            and t.get("status") in ("pending", "in_progress")
        ]

        if pending_experiments:
            self.log(f"Found {len(pending_experiments)} pending experiments", "DECISION")
            return "RUN_EXPERIMENTS"

        # æ£€æŸ¥ç“¶é¢ˆæ˜¯å¦éœ€è¦å®éªŒçªç ´
        if "Technical" in bottleneck and score < 7.5:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰å®éªŒä»»åŠ¡
            all_writing = all(
                t.get("type") == "WRITING_ONLY"
                for t in issues if t.get("status") != "completed"
            )
            if all_writing:
                self.log("Technical Quality bottleneck with no experiments - forcing experiment planning", "DECISION")
                return "TRIGGER_EXPERIMENT_PLANNING"

        # æ£€æŸ¥æ˜¯å¦åœæ»ï¼ˆä½¿ç”¨ stagnation_countï¼Œä¸ç”¨ variance æ¡ä»¶ï¼‰
        # stagnation_count >= 5: è§¦å‘ self_repair
        # stagnation_count >= 3: ç”± Meta-Debugger å¤„ç†ï¼ˆåœ¨è¿­ä»£æœ«å°¾æ£€æŸ¥ï¼‰
        if self.memory.stagnation_count >= 5:
            self.log(f"Stagnation detected ({self.memory.stagnation_count} iterations)", "DECISION")
            return "SELF_REPAIR"

        self.log("Normal iteration", "DECISION")
        return "NORMAL_ITERATION"

    def _force_experiment_planning(self):
        """å¼ºåˆ¶ Planner æ·»åŠ å®éªŒä»»åŠ¡

        å½“ Technical Quality æ˜¯ç“¶é¢ˆä½†æ²¡æœ‰å®éªŒä»»åŠ¡æ—¶è°ƒç”¨ã€‚
        """
        self.log("Technical Quality ç“¶é¢ˆï¼Œå¼ºåˆ¶æ·»åŠ å®éªŒä»»åŠ¡", "FORCE")

        bottleneck = self._get_bottleneck()
        current_score = self.memory.scores[-1] if self.memory.scores else 0

        prompt = f"""
## å¼ºåˆ¶å®éªŒè§„åˆ’æ¨¡å¼

**è§¦å‘åŸå› **: Technical Quality æ˜¯ç“¶é¢ˆ (å½“å‰åˆ†æ•°: {current_score}/10)ï¼Œä½†å½“å‰æ²¡æœ‰å®éªŒä»»åŠ¡ã€‚

**é—®é¢˜è¯Šæ–­**:
ç“¶é¢ˆç»´åº¦: {bottleneck}
çº¯å†™ä½œä¿®æ”¹æ— æ³•çªç ´ Technical Quality ç“¶é¢ˆã€‚

**å¿…é¡»æ‰§è¡Œ**:

1. è¯»å– auto_research/state/findings.yamlï¼Œæ£€æŸ¥æœ‰å“ªäº›å®éªŒå¯ä»¥åš
2. è¯»å– auto_research/state/action_plan.yamlï¼Œäº†è§£å½“å‰ä»»åŠ¡çŠ¶æ€
3. æ£€æŸ¥ä»¥ä¸‹é€‰é¡¹ï¼š
   - æ˜¯å¦å¯ä»¥ç”¨ RAP SVDï¼ˆä¸å¼ºåˆ¶å¯¹é½ï¼‰æ¥éªŒè¯ dimension repairï¼Ÿ
   - æ˜¯å¦éœ€è¦è¡¥å…… perplexity/accuracy æ•°æ®ï¼Ÿ
   - æ˜¯å¦éœ€è¦ E2E éªŒè¯ï¼Ÿ

4. **å¿…é¡»è¾“å‡º**ï¼šæ›´æ–° action_plan.yamlï¼Œæ·»åŠ è‡³å°‘ä¸€ä¸ª EXPERIMENT_REQUIRED ä»»åŠ¡

**æ³¨æ„**ï¼š
- å¦‚æœ PaLU å› ä¸º 100% å¯¹é½æ— æ³•éªŒè¯ repairï¼Œä½¿ç”¨ RAP SVD
- å®éªŒä»»åŠ¡å¿…é¡»æ˜¯å…·ä½“å¯æ‰§è¡Œçš„ï¼ˆåŒ…å«å‘½ä»¤ã€å‚æ•°ï¼‰
"""

        self.run_agent("planner", prompt)
        self.log("å¼ºåˆ¶å®éªŒè§„åˆ’å®Œæˆ", "FORCE")

    # ==================== Meta-Debugger é›†æˆ ====================

    def run_meta_debugger(self, trigger_reason: str) -> str:
        """è¿è¡Œ Meta-Debugger è¿›è¡Œç³»ç»Ÿè¯Šæ–­å’Œä¿®å¤

        Args:
            trigger_reason: è§¦å‘åŸå› 

        Returns:
            "CONTINUE" - ç»§ç»­æ­£å¸¸è¿­ä»£
            "CONTINUE_WITH_FIX" - å·²ä¿®å¤é—®é¢˜ï¼Œç»§ç»­è¿­ä»£
            "PAUSE" - å‘ç°ä¸¥é‡é—®é¢˜ï¼Œæš‚åœè¿­ä»£
        """
        self.log(f"ğŸ” è§¦å‘ Meta-Debugger: {trigger_reason}", "META")

        # è·å–è¯Šæ–­ä¸Šä¸‹æ–‡
        diagnosis_ctx = self.memory.get_diagnosis_context()
        health_status, health_reasons = self.memory.get_health_status()

        # æ„å»ºè¯Šæ–­ prompt
        ctx_summary = f"""
## è§¦å‘åŸå› 
{trigger_reason}

## ç³»ç»Ÿå¥åº·çŠ¶æ€
çŠ¶æ€: **{health_status}**
{"åŸå› : " + ", ".join(health_reasons) if health_reasons else "æ— å¼‚å¸¸"}

## åˆ†æ•°è¶‹åŠ¿
- å½“å‰: {diagnosis_ctx['scores']['current']}/10
- æœ€é«˜: {diagnosis_ctx['scores']['best']}/10
- è¶‹åŠ¿: {diagnosis_ctx['scores']['trend']}
- æœ€è¿‘: {' â†’ '.join(f"{s:.1f}" for s in diagnosis_ctx['scores']['recent'][-5:])}

## åœæ»çŠ¶æ€
- åœæ»è®¡æ•°: {diagnosis_ctx['stagnation']['count']}
- æ˜¯å¦åœæ»: {diagnosis_ctx['stagnation']['is_stagnating']}
- åŸå› : {diagnosis_ctx['stagnation']['reason']}

## Issue é‡å¤æƒ…å†µ
- é«˜é‡å¤ (7+æ¬¡): {diagnosis_ctx['issues']['high_repeat']}
- ä¸­é‡å¤ (3+æ¬¡): {diagnosis_ctx['issues']['repeat_issues'][:5]}

## å®éªŒç©ºè½¬
- ç©ºè½¬æ¬¡æ•°: {diagnosis_ctx['experiment_empty_count']}
"""

        diagnosis_output = self.run_agent("meta_debugger", f"""
{ctx_summary}

è¯·æ‰§è¡Œå®Œæ•´çš„ç³»ç»Ÿè¯Šæ–­ï¼š

1. **è¯»å–å…³é”®çŠ¶æ€æ–‡ä»¶**:
   - auto_research/state/memory.yaml
   - auto_research/state/action_plan.yaml
   - auto_research/state/latest_review.md

2. **åˆ†ææœ€è¿‘çš„æ‰§è¡Œæ—¥å¿—** (æŸ¥çœ‹ auto_research/logs/ ç›®å½•)

3. **æ£€æŸ¥æ‰§è¡Œä¸€è‡´æ€§**:
   - è¿è¡Œ `git diff scripts/create_paper_figures.py` æ£€æŸ¥ FIGURE_CODE ä»»åŠ¡
   - è¿è¡Œ `git status` æ£€æŸ¥ä¿®æ”¹äº†å“ªäº›æ–‡ä»¶

4. **è¯†åˆ«é—®é¢˜æ¨¡å¼**:
   - æ˜¯å¦æœ‰"è®¡åˆ’æ­£ç¡®ä½†æ‰§è¡Œå¤±è´¥"çš„æƒ…å†µï¼Ÿ
   - æ˜¯å¦é™·å…¥äº†"æ–¹æ³•å¾ªç¯"ï¼Ÿ
   - æ˜¯å¦æœ‰ç­–ç•¥å‡çº§è§„åˆ™è¢«è¿åï¼Ÿ

5. **ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š** åˆ° auto_research/state/meta_diagnosis.md

6. **å¦‚æœå‘ç°æ¡†æ¶ bugï¼Œç›´æ¥ä¿®å¤**:
   - ä¿®æ”¹ auto_research/memory.py
   - ä¿®æ”¹ auto_research/orchestrator.py
   - ä¿®æ”¹ auto_research/agents/*.prompt
   - é‡ç½® memory.yaml ä¸­çš„é”™è¯¯ç´¯ç§¯

**é‡è¦**: è¯Šæ–­è¦æ‰¾åˆ°æ ¹å› ï¼Œä¸åªæ˜¯ç—‡çŠ¶ã€‚ä¿®å¤è¦å…·ä½“ï¼Œä¸åªæ˜¯å»ºè®®ã€‚
""", timeout=1800)  # 30 åˆ†é’Ÿè¶…æ—¶

        # è¯»å–è¯Šæ–­æŠ¥å‘Šå¹¶è§£æçŠ¶æ€
        # æ³¨æ„: Meta-Debugger æ°¸è¿œä¸ä¼šå¯¼è‡´ PAUSEã€‚å®ƒçš„èŒè´£æ˜¯è¯Šæ–­å’Œä¿®å¤ï¼Œ
        # ä¸æ˜¯åœæ­¢ç³»ç»Ÿã€‚å³ä½¿æŠ¥å‘Šä¸­åŒ…å« "CRITICAL" æˆ– "éœ€è¦äººå·¥" ç­‰å­—æ ·ï¼Œ
        # è¿™åªæ˜¯è¯Šæ–­æè¿°ï¼Œä¸åº”é˜»æ­¢è¿­ä»£ç»§ç»­ã€‚
        diagnosis_file = PROJECT_DIR / "auto_research/state/meta_diagnosis.md"
        if diagnosis_file.exists():
            try:
                diagnosis_file.read_text()  # ç¡®è®¤æ–‡ä»¶å¯è¯»
                self.log("âš ï¸ Meta-Debugger å·²å®Œæˆè¯Šæ–­ï¼Œç»§ç»­è¿­ä»£", "WARNING")
                # é‡æ–°åŠ è½½ memory ä»¥è·å–å¯èƒ½çš„ä¿®å¤
                self.memory.load()
                return "CONTINUE_WITH_FIX"
            except Exception as e:
                self.log(f"è¯»å–è¯Šæ–­æŠ¥å‘Šå¤±è´¥: {e}", "ERROR")

        return "CONTINUE"

    def check_and_trigger_meta_debug(self) -> str:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘ Meta-Debuggerï¼Œå¦‚æœæ˜¯åˆ™è¿è¡Œ

        Returns:
            "CONTINUE" - ç»§ç»­æ­£å¸¸è¿­ä»£
            "CONTINUE_WITH_FIX" - å·²ä¿®å¤é—®é¢˜ï¼Œç»§ç»­è¿­ä»£
            "PAUSE" - å‘ç°ä¸¥é‡é—®é¢˜ï¼Œæš‚åœè¿­ä»£
        """
        should_trigger, reason = self.memory.should_trigger_meta_debug()
        if should_trigger:
            return self.run_meta_debugger(reason)
        return "CONTINUE"

    def self_repair(self, stagnation_reason: str) -> bool:
        """è‡ªæˆ‘ä¿®å¤ï¼šåœæ»æ—¶è‡ªåŠ¨è®© Planner é‡æ–°è§„åˆ’ç­–ç•¥

        å¢å¼ºç‰ˆï¼šåŒ…å«å…ƒåæ€æ£€æŸ¥ - å¦‚æœä¸Šæ¬¡ä¿®å¤æ— æ•ˆï¼Œå‡çº§ç­–ç•¥è€Œä¸æ˜¯é‡å¤åŒæ ·çš„æ–¹æ³•ã€‚

        Args:
            stagnation_reason: åœæ»åŸå› æè¿°

        Returns:
            True if repair was attempted
        """
        self.log("å¯åŠ¨è‡ªæˆ‘ä¿®å¤æµç¨‹...", "REPAIR")

        # è·å–å½“å‰çŠ¶æ€ä¿¡æ¯
        current_score = self.memory.scores[-1] if self.memory.scores else 0.0
        stagnation_count = self.memory.stagnation_count
        bottleneck = self._get_bottleneck()

        # å…ƒåæ€æ£€æŸ¥ï¼šä¸Šæ¬¡ä¿®å¤æ˜¯å¦æœ‰æ•ˆï¼Ÿ
        last_repair_effective, ineffective_reason = self.memory.was_last_repair_effective()
        repeat_issues = self.memory.get_repeat_issues(threshold=3)

        self.log(f"ç“¶é¢ˆç»´åº¦: {bottleneck}", "REPAIR")
        if not last_repair_effective:
            self.log(f"âš ï¸ å…ƒåæ€è­¦å‘Š: ä¸Šæ¬¡ä¿®å¤æ— æ•ˆ - {ineffective_reason}", "REPAIR")
        if repeat_issues:
            self.log(f"âš ï¸ é‡å¤ Issues: {[r[0] for r in repeat_issues]}", "REPAIR")

        # æ„å»ºä¿®å¤ promptï¼ˆå¸¦å…ƒåæ€å’Œç“¶é¢ˆæ„ŸçŸ¥ï¼‰
        meta_reflection = ""
        if not last_repair_effective or repeat_issues:
            meta_reflection = f"""
### âš ï¸ å…ƒåæ€è­¦å‘Š - å¿…é¡»æ¢æ–¹æ³•ï¼

**ä¸Šæ¬¡ä¿®å¤æ— æ•ˆ**: {ineffective_reason}

**é‡å¤å‡ºç°çš„ Issues**ï¼ˆè¿™äº›é—®é¢˜å·²ç»å°è¯•ä¿®å¤å¤šæ¬¡ä½†ä»æœªè§£å†³ï¼‰:
"""
            for issue_id, count in repeat_issues:
                meta_reflection += f"- **{issue_id}**: å‡ºç° {count} æ¬¡\n"

            meta_reflection += """
**å¼ºåˆ¶è¦æ±‚**ï¼š
1. ä¸è¦ä½¿ç”¨ä¸ä¹‹å‰ç›¸åŒçš„ä¿®å¤æ–¹æ³•
2. åˆ†æä¸ºä»€ä¹ˆä¹‹å‰çš„ä¿®å¤æ— æ•ˆ
3. é‡‡ç”¨å®Œå…¨ä¸åŒçš„ç­–ç•¥ï¼š
   - å¦‚æœä¹‹å‰æ˜¯æ”¹æ–‡å­— â†’ ç°åœ¨è¦è·‘å®éªŒ
   - å¦‚æœä¹‹å‰æ˜¯è°ƒæ ¼å¼ â†’ ç°åœ¨è¦æ”¹ Python ä»£ç é‡æ–°ç”Ÿæˆå›¾è¡¨
   - å¦‚æœå›¾è¡¨é—®é¢˜åå¤å‡ºç° â†’ å¿…é¡»ä½¿ç”¨ FIGURE_CODE_REQUIREDï¼ˆä¿®æ”¹ç»˜å›¾è„šæœ¬å¹¶é‡æ–°è¿è¡Œï¼‰
"""

        repair_prompt = f"""
## è‡ªæˆ‘ä¿®å¤æ¨¡å¼ - ç“¶é¢ˆçªç ´

**åœæ»åŸå› **: {stagnation_reason}
**å½“å‰åˆ†æ•°**: {current_score}/10
**ç›®æ ‡åˆ†æ•°**: {PAPER_ACCEPT_THRESHOLD}/10
**è¿ç»­åœæ»æ¬¡æ•°**: {stagnation_count}
**ç“¶é¢ˆç»´åº¦**: {bottleneck}
{meta_reflection}

### ç“¶é¢ˆåˆ†æ

æ ¹æ®ç“¶é¢ˆç»´åº¦å†³å®šä¿®å¤ç­–ç•¥ï¼š

| ç“¶é¢ˆ | ç­–ç•¥ |
|------|------|
| Technical Quality | **å¿…é¡»æ·»åŠ å®éªŒä»»åŠ¡**ï¼ˆçº¯å†™ä½œæ— æ³•çªç ´ï¼‰ |
| Presentation | é‡ç‚¹æ”¹è¿›å›¾è¡¨ï¼ˆä½¿ç”¨ FIGURE_CODE_REQUIREDï¼‰|
| Innovation | é‡æ–° frame contribution |
| Writing Quality | é‡å†™å…³é”®ç« èŠ‚ |

### å¿…é¡»æ‰§è¡Œçš„æ­¥éª¤

1. è¯»å– auto_research/state/action_plan.yamlï¼Œåˆ†æå½“å‰ä»»åŠ¡ç»“æ„
2. è¯»å– auto_research/state/latest_review.mdï¼Œäº†è§£ Reviewer çš„å…·ä½“å»ºè®®
3. æ£€æŸ¥é‡å¤ Issuesï¼Œåˆ†æä¹‹å‰çš„ä¿®å¤ä¸ºä»€ä¹ˆæ— æ•ˆ

### å¼ºåˆ¶è¦æ±‚

- å¦‚æœç“¶é¢ˆæ˜¯ **Technical Quality** ä¸” < 7.5ï¼š
  - å¿…é¡»æ·»åŠ  EXPERIMENT_REQUIRED ä»»åŠ¡

- å¦‚æœç“¶é¢ˆæ˜¯ **Presentation** æˆ–å›¾è¡¨ç›¸å…³ Issues é‡å¤å‡ºç°ï¼š
  - å¿…é¡»ä½¿ç”¨ FIGURE_CODE_REQUIREDï¼ˆä¸æ˜¯ WRITING_ONLYï¼ï¼‰
  - å¿…é¡»ä¿®æ”¹ scripts/create_paper_figures.py
  - å¿…é¡»è¿è¡Œè„šæœ¬é‡æ–°ç”Ÿæˆå›¾è¡¨

- å¦‚æœæ‰€æœ‰ä»»åŠ¡éƒ½æ˜¯ WRITING_ONLYï¼š
  - è¿™æ˜¯å±é™©ä¿¡å·ï¼Œå¿…é¡»æ·»åŠ å®éªŒæˆ– FIGURE_CODE ä»»åŠ¡

**é‡è¦**ï¼šè¿™æ˜¯è‡ªåŠ¨è§¦å‘çš„ä¿®å¤æµç¨‹ï¼Œä½ éœ€è¦è‡ªä¸»å†³ç­–ï¼Œä¸è¦ç­‰å¾…äººå·¥æŒ‡ç¤ºã€‚

**è¾“å‡º**ï¼šæ›´æ–° auto_research/state/action_plan.yamlï¼Œç¡®ä¿æœ‰é’ˆå¯¹ {bottleneck} ç“¶é¢ˆçš„çªç ´ä»»åŠ¡ã€‚
"""

        # è°ƒç”¨ Planner è¿›è¡Œè‡ªæˆ‘ä¿®å¤
        self.run_agent("planner", repair_prompt)

        # æ ‡è®°è¿™æ¬¡ä¿®å¤å°è¯•ï¼ˆç”¨äºä¸‹æ¬¡éªŒè¯ï¼‰
        self.memory.mark_repair_attempt(self.iteration)

        # ä¿®å¤åä¸é‡ç½®åœæ»è®¡æ•° â€” è®© Meta-Debugger æœ‰æœºä¼šè¢«è§¦å‘
        # self_repair æœ¬èº«å°±æ˜¯ä¸€ç§"å°è¯•"ï¼Œå¦‚æœè¿ç»­ä¿®å¤éƒ½æ— æ•ˆï¼Œ
        # stagnation_count ä¼šç»§ç»­ç´¯ç§¯ï¼Œæœ€ç»ˆè§¦å‘æ›´å¼ºåŠ›çš„ Meta-Debugger
        if last_repair_effective:
            # ä¿®å¤æœ‰æ•ˆæ—¶æ‰å‡å°‘è®¡æ•°
            self.memory.stagnation_count = max(0, stagnation_count - 3)
            self.log(f"ä¿®å¤æœ‰æ•ˆï¼Œåœæ»è®¡æ•°å‡å°‘3: {stagnation_count} â†’ {self.memory.stagnation_count}", "REPAIR")
        else:
            # ä¿®å¤æ— æ•ˆæ—¶ä¸å‡å°‘è®¡æ•°ï¼Œè®©å®ƒç»§ç»­ç´¯ç§¯
            self.log(f"ä¸Šæ¬¡ä¿®å¤æ— æ•ˆï¼Œåœæ»è®¡æ•°ä¿æŒä¸å˜: {stagnation_count}", "REPAIR")

        self.memory.save()

        self.log("è‡ªæˆ‘ä¿®å¤å®Œæˆ", "REPAIR")
        return True

    def run_paper_iteration(self) -> bool:
        """æ‰§è¡Œè®ºæ–‡å®¡ç¨¿è¿­ä»£ï¼Œè¿”å›æ˜¯å¦åº”è¯¥ç»§ç»­"""
        self.iteration += 1
        paper_state = self.load_paper_state()
        paper_requirements = self.load_paper_requirements()
        current_score = paper_state.get("current_score", 0)

        # è¿­ä»£æ ‡é¢˜
        self.log("", "RAW")
        self.log_section(f"ITERATION {self.iteration}/{self.max_iterations}  |  Score: {current_score}/10 â†’ ?  |  Target: {PAPER_ACCEPT_THRESHOLD}/10")

        # é˜¶æ®µè®¡æ•°ï¼ˆæ ¹æ®æ˜¯å¦é¦–æ¬¡è¿­ä»£åŠ¨æ€è°ƒæ•´ï¼‰
        total_phases = 6 if self.iteration == 1 else 5
        phase_num = 0

        # 0. é¦–æ¬¡è¿­ä»£ï¼šç”Ÿæˆå›¾è¡¨å¹¶è®¾ç½®åŸºæœ¬ç»“æ„
        if self.iteration == 1:
            phase_num += 1
            self.log_phase(phase_num, total_phases, "Initialize (first run)")
            self.log_step("Generating paper figures...", "progress")
            self.generate_figures()

            # è®© writer å®Œæˆåˆå§‹è®¾ç½®ï¼ˆä½œè€…ä¿¡æ¯ã€å›¾è¡¨å¼•ç”¨ç­‰ï¼‰
            req_summary = yaml.dump(paper_requirements, allow_unicode=True) if paper_requirements else "æ— ç‰¹æ®Šéœ€æ±‚"
            self.run_agent(
                "writer",
                f"""è¿™æ˜¯è®ºæ–‡å®¡ç¨¿çš„ç¬¬ä¸€æ¬¡è¿­ä»£ã€‚è¯·å®Œæˆä»¥ä¸‹åˆå§‹åŒ–å·¥ä½œï¼š

1. æ›´æ–° Latex/main.tex ä¸­çš„ä½œè€…ä¿¡æ¯ï¼ˆæ ¹æ® paper_requirements.yamlï¼‰
2. ç¡®ä¿æ‰€æœ‰ç”Ÿæˆçš„å›¾è¡¨ï¼ˆLatex/figures/fig*.pdfï¼‰éƒ½æ­£ç¡®å¼•ç”¨åˆ°è®ºæ–‡ä¸­
3. æ£€æŸ¥è®ºæ–‡ç»“æ„æ˜¯å¦å®Œæ•´
4. ç¡®ä¿ç¬¦åˆ EuroMLSys SIGPLAN åŒæ æ ¼å¼ï¼ˆæ­£æ–‡å…­é¡µï¼Œå¼•ç”¨å’Œé™„å½•ä¸é™ï¼‰

è®ºæ–‡éœ€æ±‚é…ç½®ï¼š
```yaml
{req_summary}
```

å‚è€ƒ paper_example/ ç›®å½•ä¸­çš„é«˜è´¨é‡è®ºæ–‡ã€‚""",
                timeout=3600,
            )
            self.log_phase(phase_num, total_phases, "Initialize (first run)", "end")

        # 1. ç¼–è¯‘å½“å‰ç‰ˆæœ¬çš„ LaTeX
        phase_num += 1
        self.log_phase(phase_num, total_phases, "Compile LaTeX")
        self.log_step("Compiling LaTeX...", "progress")
        if not self.compile_latex():
            self.log_step("LaTeX compilation failed, fixing...", "warning")
            self.run_agent("writer", "LaTeX ç¼–è¯‘å¤±è´¥ï¼Œè¯·ä¿®å¤è¯­æ³•é”™è¯¯å¹¶ç¡®ä¿èƒ½æ­£ç¡®ç¼–è¯‘")
            if not self.compile_latex():
                self.log_step("Still cannot compile, skipping iteration", "error")
                self.log_phase(phase_num, total_phases, "Compile LaTeX", "end")
                return True
        self.log_step("PDF generated successfully", "success")
        self.log_phase(phase_num, total_phases, "Compile LaTeX", "end")

        # 2. è½¬æ¢ PDF ä¸ºå›¾åƒç”¨äºè§†è§‰å®¡æ ¸
        page_images = self.pdf_to_images()
        visual_review_section = ""
        if page_images:
            visual_review_section = f"""

## è§†è§‰å®¡æ ¸

è¯·ä½¿ç”¨ Read å·¥å…·è¯»å–ä»¥ä¸‹è®ºæ–‡é¡µé¢å›¾åƒï¼Œè¿›è¡Œè§†è§‰æ•ˆæœå®¡æ ¸ï¼š
{chr(10).join(f'- {img}' for img in page_images)}

é‡ç‚¹æ£€æŸ¥ï¼š
- å›¾è¡¨å¤§å°æ˜¯å¦åˆé€‚ï¼Œå­—ä½“æ˜¯å¦æ¸…æ™°å¯è¯»
- æ’ç‰ˆæ˜¯å¦ä¸“ä¸šï¼ˆå¯¹é½ã€é—´è·ã€è¾¹è·ï¼‰
- ä¿¡æ¯å¯†åº¦æ˜¯å¦é€‚ä¸­
- æ•´ä½“è§†è§‰æ•ˆæœæ˜¯å¦è¾¾åˆ° research publication æ°´å¹³
"""

        # 3. Reviewer Agent å®¡ç¨¿
        phase_num += 1
        self.log_phase(phase_num, total_phases, "Review Paper")
        review_output = self.run_agent(
            "reviewer",
            f"""è¯·å®¡é˜…å½“å‰è®ºæ–‡ Latex/main.tex å’Œç”Ÿæˆçš„ Latex/main.pdfã€‚

æ ¹æ® EuroMLSys æ ‡å‡†è¿›è¡Œè¯„å®¡ï¼š
- æŠ€æœ¯è´¨é‡ (40%)
- è®ºæ–‡å‘ˆç° (30%)
- åˆ›æ–°æ€§ (20%)
- å†™ä½œè´¨é‡ (10%)
{visual_review_section}
è¾“å‡ºè¯¦ç»†çš„å®¡ç¨¿æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
1. æ€»ä½“è¯„åˆ† (X/10)
2. å„é¡¹è¯„åˆ†
3. Major Issuesï¼ˆå¿…é¡»ä¿®æ”¹ï¼‰
4. Minor Issuesï¼ˆå»ºè®®ä¿®æ”¹ï¼‰
5. å…·ä½“æ”¹è¿›å»ºè®®

å°†å®¡ç¨¿æŠ¥å‘Šä¿å­˜åˆ° auto_research/state/latest_review.md""",
            timeout=2400,  # 40 åˆ†é’Ÿ
        )

        # è§£æè¯„åˆ†
        score = self.parse_review_score(review_output)
        score_delta = score - current_score
        delta_str = f"+{score_delta:.1f}" if score_delta >= 0 else f"{score_delta:.1f}"
        self.log_step(f"Score: {score}/10 ({delta_str} from last)", "success" if score_delta >= 0 else "warning")

        # è®°å½• issues ç”¨äºé‡å¤è¿½è¸ªï¼ˆè‡ªæ£€æœºåˆ¶ï¼‰
        issue_ids = self.extract_issue_ids()
        self.memory.record_issues(issue_ids, self.iteration)

        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤å‡ºç°çš„é—®é¢˜ï¼ˆè‡ªæ£€è­¦å‘Šï¼‰
        repeat_issues = self.memory.get_repeat_issues(threshold=3)
        if repeat_issues:
            self.log("âš ï¸ è‡ªæ£€è­¦å‘Šï¼šä»¥ä¸‹ issues é‡å¤å‡ºç° 3+ æ¬¡ï¼Œè¯´æ˜ä¹‹å‰çš„ä¿®å¤æ— æ•ˆï¼", "WARN")
            for issue_id, count in repeat_issues:
                self.log(f"  - {issue_id}: å‡ºç° {count} æ¬¡", "WARN")
            self.log("å»ºè®®ï¼šéœ€è¦æ¢ä¸€ç§å®Œå…¨ä¸åŒçš„æ–¹æ³•", "WARN")

        self.log_phase(phase_num, total_phases, "Review Paper", "end")

        # æ›´æ–°è®ºæ–‡çŠ¶æ€
        paper_state["reviews"].append({
            "iteration": self.iteration,
            "timestamp": datetime.now().isoformat(),
            "score": score,
            "log": str(self.log_file),
        })
        paper_state["current_score"] = score

        # æ£€æŸ¥æ˜¯å¦è¾¾æ ‡
        if score >= PAPER_ACCEPT_THRESHOLD:
            self.log("", "RAW")
            self.log_section(f"PAPER ACCEPTED!  Score: {score}/10 >= {PAPER_ACCEPT_THRESHOLD}/10", "â˜…")
            paper_state["status"] = "accepted"
            self.save_paper_state(paper_state)
            self._last_score = score
            self.git_commit(f"ACCEPTED: Final score {score}/10")
            self.send_notification(
                "Paper Accepted",
                f"Paper achieved score {score}/10, meeting the threshold of {PAPER_ACCEPT_THRESHOLD}/10!"
            )
            return False

        # åŠ¨æ€æµç¨‹é€‰æ‹©å™¨ï¼šæ ¹æ®å½“å‰çŠ¶æ€å†³å®šä¸‹ä¸€æ­¥
        phase_num += 1
        self.log_phase(phase_num, total_phases, "Plan & Execute Improvements")

        next_action = self.decide_next_action()
        self.log(f"Dynamic decision: {next_action}", "DECISION")

        if next_action == "TRIGGER_EXPERIMENT_PLANNING":
            # Technical Quality æ˜¯ç“¶é¢ˆä½†æ²¡æœ‰å®éªŒä»»åŠ¡ï¼Œå¼ºåˆ¶æ·»åŠ 
            self._force_experiment_planning()

        elif next_action == "SELF_REPAIR":
            # æ£€æµ‹åˆ°åœæ»ï¼Œè§¦å‘è‡ªæˆ‘ä¿®å¤
            is_stagnating, stagnation_reason = self.memory.is_stagnating()
            self.self_repair(stagnation_reason)

        # æ— è®ºå“ªç§æƒ…å†µï¼Œéƒ½è¿è¡Œ planner cycle
        planner_success = self.run_planner_cycle(review_output)

        if not planner_success:
            # Planner å¾ªç¯å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•çš„ Writer ä¿®æ”¹
            self.log_step("Planner cycle incomplete, using fallback", "warning")
            req_str = ""
            if paper_requirements:
                quality_reqs = paper_requirements.get("quality_requirements", [])
                if quality_reqs:
                    req_str = "\n\nå…³é”®è´¨é‡è¦æ±‚ï¼š\n" + "\n".join(f"- {r}" for r in quality_reqs)

            self.run_agent(
                "writer",
                f"""è¯·é˜…è¯»æœ€æ–°çš„å®¡ç¨¿æŠ¥å‘Š auto_research/state/latest_review.mdï¼Œ
æ ¹æ®å®¡ç¨¿æ„è§æ”¹è¿›è®ºæ–‡ï¼š

1. é¦–å…ˆå¤„ç†æ‰€æœ‰ Major Issues
2. ç„¶åå¤„ç† Minor Issues
3. æ”¹è¿›å›¾è¡¨è´¨é‡å’Œä¿¡æ¯å¯†åº¦
4. ç¡®ä¿ç¬¦åˆ EuroMLSys åŒæ æ ¼å¼ï¼ˆæ­£æ–‡å…­é¡µï¼Œå¼•ç”¨å’Œé™„å½•ä¸é™ï¼‰

æ³¨æ„ï¼š
- ä¿æŒè®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®ä¸å˜
- æ¯æ¬¡æ”¹è¿›åç¡®ä¿ LaTeX èƒ½ç¼–è¯‘é€šè¿‡
- æ›´æ–° report.md ä¿æŒåŒæ­¥{req_str}""",
                timeout=3600,
            )
        self.log_phase(phase_num, total_phases, "Plan & Execute Improvements", "end")

        # éªŒè¯æ”¹è¿›
        phase_num += 1
        self.log_phase(phase_num, total_phases, "Validate Changes")
        self.run_agent("validator", "éªŒè¯è®ºæ–‡æ”¹è¿›æ˜¯å¦ç¬¦åˆå®¡ç¨¿è¦æ±‚")
        self.log_phase(phase_num, total_phases, "Validate Changes", "end")

        self.save_paper_state(paper_state)
        self._last_score = score

        # è¿­ä»£æ€»ç»“
        self.log("", "RAW")
        gap = PAPER_ACCEPT_THRESHOLD - score
        status = "CONTINUE" if gap > 0 else "ACCEPTED"
        self.log_summary_box(f"Iteration {self.iteration} Summary", [
            f"Score: {score}/10 (target: {PAPER_ACCEPT_THRESHOLD}/10)",
            f"Gap: {gap:.1f} points remaining" if gap > 0 else "Target reached!",
            f"Status: {status}",
        ], inside_phase=False)

        # 8.5 è®°å½•åˆ° Memory ç³»ç»Ÿï¼ˆæç®€ç‰ˆï¼šåªè®°å½•åˆ†æ•°ï¼‰
        self.record_score_to_memory(score)

        # 9. æ¸…ç†å·¥ä½œåŒº
        self.cleanup_workspace()

        # 10. Git Commitï¼ˆæ¯è½®è¿­ä»£éƒ½æäº¤ï¼‰
        self.git_commit(f"Iteration {self.iteration}: score {score}/10")

        # ä¿å­˜æ£€æŸ¥ç‚¹
        self.save_checkpoint()

        # 11. åœæ»æ£€æµ‹ä¸è‡ªæˆ‘ä¿®å¤
        # æ³¨æ„ï¼šåªåœ¨ stagnation_count >= 5 æ—¶è§¦å‘ self_repair
        # stagnation_count < 5 æ—¶ç”± Meta-Debugger åœ¨æ­¥éª¤ 12 å¤„ç†
        is_stagnating, stagnation_reason = self.memory.is_stagnating()
        if is_stagnating:
            self.log(f"âš ï¸ åœæ»æ£€æµ‹: {stagnation_reason} (stagnation_count={self.memory.stagnation_count})", "WARN")

            if self.memory.stagnation_count >= 5:
                # é«˜åœæ»ï¼šè§¦å‘è‡ªæˆ‘ä¿®å¤
                self.log("è§¦å‘è‡ªæˆ‘ä¿®å¤...", "REPAIR")
                self.self_repair(stagnation_reason)
            else:
                # ä½åœæ»ï¼šä»…è®°å½•ï¼Œäº¤ç»™ Meta-Debugger å¤„ç†
                self.log("åœæ»è®¡æ•°è¾ƒä½ï¼Œäº¤ç»™ Meta-Debugger å¤„ç†", "WARN")

            # å‘é€é€šçŸ¥
            if self.memory.stagnation_count >= 10:
                self.send_notification(
                    "AutoGAC è‡ªæˆ‘ä¿®å¤",
                    f"æ£€æµ‹åˆ°åœæ»å¹¶å·²è‡ªåŠ¨é‡æ–°è§„åˆ’ç­–ç•¥ã€‚\n"
                    f"åŸå› : {stagnation_reason}\n"
                    f"å½“å‰è¯„åˆ†: {score}/10"
                )

        # 12. Meta-Debugger æ£€æŸ¥ï¼ˆæ›´æ·±å±‚æ¬¡çš„ç³»ç»Ÿè¯Šæ–­ï¼‰
        # æ³¨æ„: Meta-Debugger ä¸å†èƒ½åœæ­¢è¿­ä»£ï¼Œåªèƒ½è¯Šæ–­å’Œä¿®å¤
        meta_result = self.check_and_trigger_meta_debug()
        if meta_result == "CONTINUE_WITH_FIX":
            self.log("âœ… Meta-Debugger å·²ä¿®å¤ç³»ç»Ÿé—®é¢˜", "META")

        return True

    def run_iteration(self) -> bool:
        """æ‰§è¡Œä¸€æ¬¡è¿­ä»£ï¼Œè¿”å›æ˜¯å¦åº”è¯¥ç»§ç»­"""
        self.iteration += 1
        self.log(f"\n{'='*60}")
        self.log(f"Iteration {self.iteration} started at {datetime.now()}")
        self.log(f"{'='*60}\n")

        # 1. åŠ è½½çŠ¶æ€
        state = self.load_state()
        phase = self.get_current_phase(state)
        self.log(f"Current phase: {phase}")

        if phase == "completed":
            self.log("All phases completed!")
            self.send_notification("Research Completed", "All research phases have been completed!")
            return False

        # 2. æ ¹æ®é˜¶æ®µæ‰§è¡Œä¸åŒçš„ Agent æµç¨‹
        if phase == "C1_quantify":
            # C1: è¡¥å……é‡åŒ–å®éªŒ
            self.run_agent("experimenter", "æ£€æŸ¥ C1 é˜¶æ®µæ˜¯å¦éœ€è¦æ›´å¤šå®éªŒï¼Œå¦‚æœéœ€è¦ï¼Œè®¾è®¡å¹¶æäº¤")
            self.wait_for_slurm()
            self.run_agent("researcher", "åˆ†æ C1 å®éªŒç»“æœï¼Œåˆ¤æ–­æ˜¯å¦è¶³å¤Ÿé‡åŒ–ç»´åº¦åå¡Œç°è±¡")

        elif phase == "C2_probe":
            # C2: åŸå› æ¢ç©¶ï¼ˆé‡ç‚¹ï¼‰
            sub_task = self._get_c2_subtask(state)
            self.log(f"C2 sub-task: {sub_task}")

            self.run_agent("experimenter", f"é’ˆå¯¹ C2 çš„ {sub_task}ï¼Œè®¾è®¡å¹¶æäº¤å®éªŒ")
            self.wait_for_slurm()
            self.run_agent("researcher", f"åˆ†æ {sub_task} çš„å®éªŒç»“æœï¼ŒéªŒè¯æˆ–æ¨ç¿»å‡è®¾")

        elif phase == "C3_formulate":
            # C3: å½¢å¼åŒ–é—®é¢˜
            self.run_agent("researcher", "åŸºäº C2 å‘ç°ï¼Œå½¢å¼åŒ– Shape Contract å®šä¹‰")

        elif phase == "C4_solver":
            # C4: å®ç°è§£å†³æ–¹æ¡ˆ
            self.run_agent("experimenter", "å®ç° dimension repair ç®—æ³•å¹¶éªŒè¯")

        elif phase == "C5_validation":
            # C5: ç«¯åˆ°ç«¯éªŒè¯
            self.run_agent("experimenter", "è®¾è®¡å¹¶è¿è¡Œç«¯åˆ°ç«¯ LLM æ¨ç†å¯¹æ¯”å®éªŒ")
            self.wait_for_slurm()
            self.run_agent("researcher", "åˆ†æç«¯åˆ°ç«¯éªŒè¯ç»“æœ")

        # 3. æ›´æ–°æŠ¥å‘Šå’Œè®ºæ–‡
        self.run_agent("writer", "æ ¹æ®æœ€æ–°å‘ç°æ›´æ–° report.md å’Œ Latex")

        # 4. éªŒè¯å®Œæˆåº¦
        validation_output = self.run_agent("validator", "æ£€æŸ¥å½“å‰ç ”ç©¶å®Œæˆåº¦")

        # 5. æ£€æŸ¥æ˜¯å¦é˜¶æ®µå®Œæˆï¼Œå‘é€é€šçŸ¥
        new_state = self.load_state()
        new_phase = self.get_current_phase(new_state)
        if new_phase != phase:
            self.send_notification(
                f"Phase {phase} Completed",
                f"Phase {phase} has been completed. Moving to {new_phase}."
            )

        # 6. æ›´æ–°è¿­ä»£è®°å½•
        new_state["current_iteration"]["number"] = self.iteration
        new_state["history"].append({
            "iteration": self.iteration,
            "timestamp": datetime.now().isoformat(),
            "phase": phase,
            "log": str(self.log_file),
        })
        self.save_state(new_state)

        self.log(f"Iteration {self.iteration} completed\n")

        # ä¼‘æ¯ä¸€æ®µæ—¶é—´ï¼ˆé¿å… API é™æµå’Œé¢åº¦æ¶ˆè€—è¿‡å¿«ï¼‰
        self.log("Waiting 5 minutes before next iteration...")
        time.sleep(300)  # 5 åˆ†é’Ÿé—´éš”ï¼Œé™ä½ API è°ƒç”¨é¢‘ç‡

        return True

    def _get_c2_subtask(self, state: dict) -> str:
        """è·å– C2 é˜¶æ®µå½“å‰åº”è¯¥åšçš„å­ä»»åŠ¡"""
        c2 = state.get("phases", {}).get("C2_probe", {})
        sub_tasks = c2.get("sub_tasks", [])

        for task in sub_tasks:
            if task.get("status") in ["pending", "partial"]:
                return task.get("name", "unknown")

        return "all sub-tasks completed"

    def run(self):
        """ä¸»å¾ªç¯"""
        self.log_section(f"AutoGAC Started  |  Mode: {self.mode.upper()}  |  {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        self.log(f"Max iterations: {self.max_iterations}  |  Max time: {self.max_end_time.strftime('%Y-%m-%d %H:%M')}", "RAW")
        self.log(f"Log: {self.log_file}", "RAW")
        self.log("", "RAW")

        self.send_notification(
            f"{self.mode.capitalize()} Mode Started",
            f"Automated {self.mode} system started.\nMax iterations: {self.max_iterations}\nLog: {self.log_file}"
        )

        try:
            while (
                datetime.now() < self.max_end_time
                and self.iteration < self.max_iterations
            ):
                if self.mode == "paper":
                    should_continue = self.run_paper_iteration()
                else:
                    should_continue = self.run_iteration()

                if not should_continue:
                    break

        except KeyboardInterrupt:
            self.log("", "RAW")
            self.log_section("INTERRUPTED BY USER", "!")
        except Exception as e:
            self.log("", "RAW")
            self.log_section(f"ERROR: {str(e)[:50]}", "!")
            self.send_notification("Error", f"{self.mode.capitalize()} system encountered an error: {e}")
            raise

        # ç»“æŸæ‘˜è¦
        self.log("", "RAW")
        if self.mode == "paper":
            paper_state = self.load_paper_state()
            final_score = paper_state.get('current_score', 0)
            status = paper_state.get('status', 'unknown')
            self.log_section(f"AutoGAC Finished  |  Score: {final_score}/10  |  Status: {status.upper()}")
        else:
            self.log_section(f"AutoGAC Finished  |  Iterations: {self.iteration}")
        self.log(f"Total iterations: {self.iteration}", "RAW")


def main():
    parser = argparse.ArgumentParser(description="GAC Automated Research Orchestrator")
    parser.add_argument("--mode", type=str, default="research", choices=["research", "paper"],
                        help="Mode: 'research' for experiments, 'paper' for review iterations")
    parser.add_argument("--max-days", type=float, default=3, help="Maximum runtime in days")
    parser.add_argument("--max-iterations", type=int, default=100, help="Maximum iterations")
    args = parser.parse_args()

    orchestrator = Orchestrator(
        max_days=args.max_days,
        max_iterations=args.max_iterations,
        mode=args.mode,
    )
    orchestrator.run()


if __name__ == "__main__":
    main()
